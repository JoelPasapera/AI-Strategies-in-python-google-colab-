{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyMgzgdJ3k3hQermAN9RIGMI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoelPasapera/AI-Strategies-in-python-google-colab-/blob/main/Red_neuronal_trading_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# CONFIGURACIÓN INICIAL Y INSTALACIÓN DE LIBRERÍAS\n",
        "# =============================================\n",
        "%%capture\n",
        "!pip install tensorflow #==2.13.0\n",
        "!pip install keras-tuner\n",
        "!pip install ta\n",
        "!pip install plotly\n",
        "!pip install yfinance\n",
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "qVTZf-3EFdko"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "xHS85FzkFgQM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# CARGA Y PREPROCESAMIENTO DE DATOS\n",
        "# =============================================\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Cargar datos\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(file_name, encoding='utf-16')\n",
        "\n",
        "print(f\"Dataset cargado: {df.shape}\")\n",
        "print(df.head())\n",
        "\n",
        "# Procesamiento de fecha\n",
        "df['date'] = pd.to_datetime(df['date'], format='%Y.%m.%d %H:%M:%S')\n",
        "df = df.sort_values('date').reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "Wun2neIJICtN",
        "outputId": "b872f979-411f-416c-c42d-0d06f5302771"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b8be092-840b-4dcb-b48b-317925bd687d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b8be092-840b-4dcb-b48b-317925bd687d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving GBPUSD_16385_minutes.csv to GBPUSD_16385_minutes (2).csv\n",
            "Dataset cargado: (11684, 5)\n",
            "                  date     open     high      low    close\n",
            "0  2025.11.14 23:00:00  1.31677  1.31745  1.31645  1.31744\n",
            "1  2025.11.14 22:00:00  1.31646  1.31707  1.31614  1.31677\n",
            "2  2025.11.14 21:00:00  1.31603  1.31676  1.31561  1.31646\n",
            "3  2025.11.14 20:00:00  1.31608  1.31632  1.31493  1.31603\n",
            "4  2025.11.14 19:00:00  1.31548  1.31630  1.31507  1.31609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CONFIGURACIONES GENERALES\n",
        "# ============================================\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Modelo Trading para GBPUSD.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/1abc123xyz\n",
        "\"\"\"\n",
        "\n",
        "# Define cuantas epocas tendrá el modelo para el entrenamiento\n",
        "EPOCHS: int = 200\n",
        "BATCH_SIZE: int = 256\n",
        "\n",
        "# Configuración para máxima performance\n",
        "tf.keras.backend.clear_session()\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Verificar GPUs\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"{len(gpus)} GPUs disponibles\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "0kSq3bdKI7oM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "trblvjJxFUv0",
        "outputId": "b1ad72e3-ccaf-4663-f4b4-a5b45b3dbfbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset después del feature engineering: (11561, 69)\n",
            "Training set: (8050, 60, 62)\n",
            "Validation set: (1150, 60, 62)\n",
            "Test set: (2301, 60, 62)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m62\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m11,968\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m326,656\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m197,120\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m263,808\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ multi_head_atten… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m197,120\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ return_1h (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ return_4h (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ return_24h (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ direction_1h        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ direction_4h        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,968</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">326,656</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ multi_head_atten… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ return_1h (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ return_4h (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ return_24h (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ direction_1h        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ direction_4h        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,292,229\u001b[0m (4.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,292,229</span> (4.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,288,517\u001b[0m (4.92 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,288,517</span> (4.92 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,712\u001b[0m (14.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> (14.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n",
            "Modelo compilado exitosamente dentro del strategy scope!\n",
            "Batch size ajustado: 256\n",
            "Iniciando entrenamiento...\n",
            "Epoch 1/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5165 - direction_1h_binary_accuracy: 0.5165 - direction_1h_loss: 0.9267 - direction_4h_accuracy: 0.5016 - direction_4h_binary_accuracy: 0.5016 - direction_4h_loss: 0.9448 - loss: 8.7549 - return_1h_loss: 2.1768 - return_1h_mae: 1.1484 - return_1h_mse: 2.1771 - return_24h_loss: 2.3179 - return_24h_mae: 1.1895 - return_24h_mse: 2.3183 - return_4h_loss: 1.9741 - return_4h_mae: 1.0948 - return_4h_mse: 1.9744\n",
            "Epoch 1: val_loss improved from inf to 2.76060, saving model to best_trading_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - direction_1h_accuracy: 0.5163 - direction_1h_binary_accuracy: 0.5163 - direction_1h_loss: 0.9258 - direction_4h_accuracy: 0.5018 - direction_4h_binary_accuracy: 0.5018 - direction_4h_loss: 0.9439 - loss: 8.7177 - return_1h_loss: 2.1610 - return_1h_mae: 1.1438 - return_1h_mse: 2.1616 - return_24h_loss: 2.3036 - return_24h_mae: 1.1855 - return_24h_mse: 2.3044 - return_4h_loss: 1.9620 - return_4h_mae: 1.0910 - return_4h_mse: 1.9627 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7048 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.7743 - val_loss: 2.7606 - val_return_1h_loss: 0.0042 - val_return_1h_mae: 0.0478 - val_return_1h_mse: 0.0034 - val_return_24h_loss: 0.0054 - val_return_24h_mae: 0.0576 - val_return_24h_mse: 0.0053 - val_return_4h_loss: 0.0201 - val_return_4h_mae: 0.1349 - val_return_4h_mse: 0.0202 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.4960 - direction_1h_binary_accuracy: 0.4960 - direction_1h_loss: 0.8478 - direction_4h_accuracy: 0.5232 - direction_4h_binary_accuracy: 0.5232 - direction_4h_loss: 0.8381 - loss: 5.4172 - return_1h_loss: 0.8790 - return_1h_mae: 0.7250 - return_1h_mse: 0.8790 - return_24h_loss: 1.0336 - return_24h_mae: 0.7854 - return_24h_mse: 1.0336 - return_4h_loss: 0.8928 - return_4h_mae: 0.7242 - return_4h_mse: 0.8929\n",
            "Epoch 2: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.4961 - direction_1h_binary_accuracy: 0.4961 - direction_1h_loss: 0.8470 - direction_4h_accuracy: 0.5231 - direction_4h_binary_accuracy: 0.5231 - direction_4h_loss: 0.8377 - loss: 5.4081 - return_1h_loss: 0.8765 - return_1h_mae: 0.7240 - return_1h_mse: 0.8766 - return_24h_loss: 1.0308 - return_24h_mae: 0.7843 - return_24h_mse: 1.0309 - return_4h_loss: 0.8893 - return_4h_mae: 0.7227 - return_4h_mse: 0.8895 - val_direction_1h_accuracy: 0.4991 - val_direction_1h_binary_accuracy: 0.4991 - val_direction_1h_loss: 0.6955 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.7487 - val_loss: 3.0996 - val_return_1h_loss: 0.1058 - val_return_1h_mae: 0.3029 - val_return_1h_mse: 0.1005 - val_return_24h_loss: 0.1468 - val_return_24h_mae: 0.3373 - val_return_24h_mse: 0.1339 - val_return_4h_loss: 0.2670 - val_return_4h_mae: 0.4663 - val_return_4h_mse: 0.2464 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - direction_1h_accuracy: 0.5162 - direction_1h_binary_accuracy: 0.5162 - direction_1h_loss: 0.7664 - direction_4h_accuracy: 0.4998 - direction_4h_binary_accuracy: 0.4998 - direction_4h_loss: 0.7974 - loss: 4.4160 - return_1h_loss: 0.6177 - return_1h_mae: 0.5931 - return_1h_mse: 0.6177 - return_24h_loss: 0.6615 - return_24h_mae: 0.6193 - return_24h_mse: 0.6615 - return_4h_loss: 0.5623 - return_4h_mae: 0.5649 - return_4h_mse: 0.5623\n",
            "Epoch 3: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - direction_1h_accuracy: 0.5160 - direction_1h_binary_accuracy: 0.5160 - direction_1h_loss: 0.7666 - direction_4h_accuracy: 0.5002 - direction_4h_binary_accuracy: 0.5002 - direction_4h_loss: 0.7969 - loss: 4.4112 - return_1h_loss: 0.6155 - return_1h_mae: 0.5923 - return_1h_mse: 0.6156 - return_24h_loss: 0.6602 - return_24h_mae: 0.6187 - return_24h_mse: 0.6602 - return_4h_loss: 0.5608 - return_4h_mae: 0.5642 - return_4h_mse: 0.5607 - val_direction_1h_accuracy: 0.5043 - val_direction_1h_binary_accuracy: 0.5043 - val_direction_1h_loss: 0.6946 - val_direction_4h_accuracy: 0.4713 - val_direction_4h_binary_accuracy: 0.4713 - val_direction_4h_loss: 0.7355 - val_loss: 2.8471 - val_return_1h_loss: 0.1035 - val_return_1h_mae: 0.2972 - val_return_1h_mse: 0.0957 - val_return_24h_loss: 0.0222 - val_return_24h_mae: 0.1167 - val_return_24h_mse: 0.0204 - val_return_4h_loss: 0.0773 - val_return_4h_mae: 0.2299 - val_return_4h_mse: 0.0739 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5066 - direction_1h_binary_accuracy: 0.5066 - direction_1h_loss: 0.7585 - direction_4h_accuracy: 0.5404 - direction_4h_binary_accuracy: 0.5404 - direction_4h_loss: 0.7423 - loss: 3.8668 - return_1h_loss: 0.4140 - return_1h_mae: 0.4881 - return_1h_mse: 0.4140 - return_24h_loss: 0.4787 - return_24h_mae: 0.5223 - return_24h_mse: 0.4787 - return_4h_loss: 0.4067 - return_4h_mae: 0.4818 - return_4h_mse: 0.4067\n",
            "Epoch 4: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5065 - direction_1h_binary_accuracy: 0.5065 - direction_1h_loss: 0.7585 - direction_4h_accuracy: 0.5404 - direction_4h_binary_accuracy: 0.5404 - direction_4h_loss: 0.7423 - loss: 3.8648 - return_1h_loss: 0.4134 - return_1h_mae: 0.4876 - return_1h_mse: 0.4134 - return_24h_loss: 0.4777 - return_24h_mae: 0.5217 - return_24h_mse: 0.4778 - return_4h_loss: 0.4058 - return_4h_mae: 0.4813 - return_4h_mse: 0.4059 - val_direction_1h_accuracy: 0.5130 - val_direction_1h_binary_accuracy: 0.5130 - val_direction_1h_loss: 0.6950 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.7627 - val_loss: 2.8073 - val_return_1h_loss: 0.0735 - val_return_1h_mae: 0.2392 - val_return_1h_mse: 0.0656 - val_return_24h_loss: 0.0182 - val_return_24h_mae: 0.1251 - val_return_24h_mse: 0.0198 - val_return_4h_loss: 0.0203 - val_return_4h_mae: 0.1172 - val_return_4h_mse: 0.0206 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5130 - direction_1h_binary_accuracy: 0.5130 - direction_1h_loss: 0.7425 - direction_4h_accuracy: 0.5221 - direction_4h_binary_accuracy: 0.5221 - direction_4h_loss: 0.7502 - loss: 3.5290 - return_1h_loss: 0.2814 - return_1h_mae: 0.3993 - return_1h_mse: 0.2814 - return_24h_loss: 0.3785 - return_24h_mae: 0.4493 - return_24h_mse: 0.3786 - return_4h_loss: 0.2716 - return_4h_mae: 0.3904 - return_4h_mse: 0.2717\n",
            "Epoch 5: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5130 - direction_1h_binary_accuracy: 0.5130 - direction_1h_loss: 0.7424 - direction_4h_accuracy: 0.5221 - direction_4h_binary_accuracy: 0.5221 - direction_4h_loss: 0.7501 - loss: 3.5275 - return_1h_loss: 0.2813 - return_1h_mae: 0.3992 - return_1h_mse: 0.2813 - return_24h_loss: 0.3775 - return_24h_mae: 0.4488 - return_24h_mse: 0.3776 - return_4h_loss: 0.2712 - return_4h_mae: 0.3901 - return_4h_mse: 0.2712 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7115 - val_direction_4h_accuracy: 0.4696 - val_direction_4h_binary_accuracy: 0.4696 - val_direction_4h_loss: 0.7545 - val_loss: 2.7644 - val_return_1h_loss: 0.0213 - val_return_1h_mae: 0.1063 - val_return_1h_mse: 0.0187 - val_return_24h_loss: 0.0122 - val_return_24h_mae: 0.0850 - val_return_24h_mse: 0.0101 - val_return_4h_loss: 0.0105 - val_return_4h_mae: 0.0879 - val_return_4h_mse: 0.0111 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5154 - direction_1h_binary_accuracy: 0.5154 - direction_1h_loss: 0.7258 - direction_4h_accuracy: 0.5325 - direction_4h_binary_accuracy: 0.5325 - direction_4h_loss: 0.7347 - loss: 3.3031 - return_1h_loss: 0.2325 - return_1h_mae: 0.3572 - return_1h_mse: 0.2325 - return_24h_loss: 0.2738 - return_24h_mae: 0.3851 - return_24h_mse: 0.2739 - return_4h_loss: 0.2038 - return_4h_mae: 0.3402 - return_4h_mse: 0.2038\n",
            "Epoch 6: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - direction_1h_accuracy: 0.5153 - direction_1h_binary_accuracy: 0.5153 - direction_1h_loss: 0.7259 - direction_4h_accuracy: 0.5326 - direction_4h_binary_accuracy: 0.5326 - direction_4h_loss: 0.7345 - loss: 3.3019 - return_1h_loss: 0.2320 - return_1h_mae: 0.3569 - return_1h_mse: 0.2321 - return_24h_loss: 0.2731 - return_24h_mae: 0.3847 - return_24h_mse: 0.2732 - return_4h_loss: 0.2035 - return_4h_mae: 0.3399 - return_4h_mse: 0.2035 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7107 - val_direction_4h_accuracy: 0.4652 - val_direction_4h_binary_accuracy: 0.4652 - val_direction_4h_loss: 0.7964 - val_loss: 2.8243 - val_return_1h_loss: 0.0231 - val_return_1h_mae: 0.1122 - val_return_1h_mse: 0.0198 - val_return_24h_loss: 0.0081 - val_return_24h_mae: 0.0781 - val_return_24h_mse: 0.0077 - val_return_4h_loss: 0.0109 - val_return_4h_mae: 0.0904 - val_return_4h_mse: 0.0119 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - direction_1h_accuracy: 0.5030 - direction_1h_binary_accuracy: 0.5030 - direction_1h_loss: 0.7229 - direction_4h_accuracy: 0.5244 - direction_4h_binary_accuracy: 0.5244 - direction_4h_loss: 0.7212 - loss: 3.1230 - return_1h_loss: 0.1665 - return_1h_mae: 0.3029 - return_1h_mse: 0.1666 - return_24h_loss: 0.2087 - return_24h_mae: 0.3336 - return_24h_mse: 0.2087 - return_4h_loss: 0.1485 - return_4h_mae: 0.2831 - return_4h_mse: 0.1485\n",
            "Epoch 7: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - direction_1h_accuracy: 0.5032 - direction_1h_binary_accuracy: 0.5032 - direction_1h_loss: 0.7228 - direction_4h_accuracy: 0.5246 - direction_4h_binary_accuracy: 0.5246 - direction_4h_loss: 0.7212 - loss: 3.1220 - return_1h_loss: 0.1663 - return_1h_mae: 0.3028 - return_1h_mse: 0.1664 - return_24h_loss: 0.2082 - return_24h_mae: 0.3332 - return_24h_mse: 0.2082 - return_4h_loss: 0.1483 - return_4h_mae: 0.2830 - return_4h_mse: 0.1483 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7090 - val_direction_4h_accuracy: 0.4626 - val_direction_4h_binary_accuracy: 0.4626 - val_direction_4h_loss: 0.8012 - val_loss: 2.8522 - val_return_1h_loss: 0.0391 - val_return_1h_mae: 0.1709 - val_return_1h_mse: 0.0341 - val_return_24h_loss: 0.0186 - val_return_24h_mae: 0.1273 - val_return_24h_mse: 0.0202 - val_return_4h_loss: 0.0127 - val_return_4h_mae: 0.0845 - val_return_4h_mse: 0.0113 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - direction_1h_accuracy: 0.5172 - direction_1h_binary_accuracy: 0.5172 - direction_1h_loss: 0.7173 - direction_4h_accuracy: 0.5463 - direction_4h_binary_accuracy: 0.5463 - direction_4h_loss: 0.7076 - loss: 2.9949 - return_1h_loss: 0.1313 - return_1h_mae: 0.2687 - return_1h_mse: 0.1313 - return_24h_loss: 0.1467 - return_24h_mae: 0.2785 - return_24h_mse: 0.1467 - return_4h_loss: 0.1185 - return_4h_mae: 0.2535 - return_4h_mse: 0.1186\n",
            "Epoch 8: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - direction_1h_accuracy: 0.5173 - direction_1h_binary_accuracy: 0.5173 - direction_1h_loss: 0.7172 - direction_4h_accuracy: 0.5466 - direction_4h_binary_accuracy: 0.5466 - direction_4h_loss: 0.7075 - loss: 2.9941 - return_1h_loss: 0.1311 - return_1h_mae: 0.2685 - return_1h_mse: 0.1311 - return_24h_loss: 0.1464 - return_24h_mae: 0.2784 - return_24h_mse: 0.1464 - return_4h_loss: 0.1184 - return_4h_mae: 0.2533 - return_4h_mse: 0.1184 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7033 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.8128 - val_loss: 2.8513 - val_return_1h_loss: 0.0327 - val_return_1h_mae: 0.1600 - val_return_1h_mse: 0.0291 - val_return_24h_loss: 0.0124 - val_return_24h_mae: 0.1043 - val_return_24h_mse: 0.0132 - val_return_4h_loss: 0.0166 - val_return_4h_mae: 0.1007 - val_return_4h_mse: 0.0153 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5185 - direction_1h_binary_accuracy: 0.5185 - direction_1h_loss: 0.7133 - direction_4h_accuracy: 0.5451 - direction_4h_binary_accuracy: 0.5451 - direction_4h_loss: 0.6981 - loss: 2.8976 - return_1h_loss: 0.0973 - return_1h_mae: 0.2319 - return_1h_mse: 0.0973 - return_24h_loss: 0.1195 - return_24h_mae: 0.2488 - return_24h_mse: 0.1195 - return_4h_loss: 0.0915 - return_4h_mae: 0.2209 - return_4h_mse: 0.0915\n",
            "Epoch 9: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5185 - direction_1h_binary_accuracy: 0.5185 - direction_1h_loss: 0.7132 - direction_4h_accuracy: 0.5453 - direction_4h_binary_accuracy: 0.5453 - direction_4h_loss: 0.6980 - loss: 2.8969 - return_1h_loss: 0.0971 - return_1h_mae: 0.2317 - return_1h_mse: 0.0971 - return_24h_loss: 0.1192 - return_24h_mae: 0.2486 - return_24h_mse: 0.1193 - return_4h_loss: 0.0913 - return_4h_mae: 0.2207 - return_4h_mse: 0.0913 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7165 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.8438 - val_loss: 2.9148 - val_return_1h_loss: 0.0268 - val_return_1h_mae: 0.1474 - val_return_1h_mse: 0.0252 - val_return_24h_loss: 0.0053 - val_return_24h_mae: 0.0681 - val_return_24h_mse: 0.0057 - val_return_4h_loss: 0.0199 - val_return_4h_mae: 0.1189 - val_return_4h_mse: 0.0184 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5256 - direction_1h_binary_accuracy: 0.5256 - direction_1h_loss: 0.7045 - direction_4h_accuracy: 0.5567 - direction_4h_binary_accuracy: 0.5567 - direction_4h_loss: 0.6965 - loss: 2.8191 - return_1h_loss: 0.0766 - return_1h_mae: 0.2033 - return_1h_mse: 0.0766 - return_24h_loss: 0.0846 - return_24h_mae: 0.2148 - return_24h_mse: 0.0846 - return_4h_loss: 0.0714 - return_4h_mae: 0.1928 - return_4h_mse: 0.0714\n",
            "Epoch 10: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5258 - direction_1h_binary_accuracy: 0.5258 - direction_1h_loss: 0.7044 - direction_4h_accuracy: 0.5570 - direction_4h_binary_accuracy: 0.5570 - direction_4h_loss: 0.6963 - loss: 2.8183 - return_1h_loss: 0.0765 - return_1h_mae: 0.2031 - return_1h_mse: 0.0765 - return_24h_loss: 0.0846 - return_24h_mae: 0.2148 - return_24h_mse: 0.0846 - return_4h_loss: 0.0712 - return_4h_mae: 0.1926 - return_4h_mse: 0.0712 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7155 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.7945 - val_loss: 2.8294 - val_return_1h_loss: 0.0130 - val_return_1h_mae: 0.1031 - val_return_1h_mse: 0.0127 - val_return_24h_loss: 0.0169 - val_return_24h_mae: 0.1210 - val_return_24h_mse: 0.0164 - val_return_4h_loss: 0.0164 - val_return_4h_mae: 0.1045 - val_return_4h_mse: 0.0144 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5371 - direction_1h_binary_accuracy: 0.5371 - direction_1h_loss: 0.7020 - direction_4h_accuracy: 0.5646 - direction_4h_binary_accuracy: 0.5646 - direction_4h_loss: 0.6936 - loss: 2.7656 - return_1h_loss: 0.0590 - return_1h_mae: 0.1767 - return_1h_mse: 0.0590 - return_24h_loss: 0.0664 - return_24h_mae: 0.1870 - return_24h_mse: 0.0664 - return_4h_loss: 0.0543 - return_4h_mae: 0.1663 - return_4h_mse: 0.0543\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5369 - direction_1h_binary_accuracy: 0.5369 - direction_1h_loss: 0.7020 - direction_4h_accuracy: 0.5648 - direction_4h_binary_accuracy: 0.5648 - direction_4h_loss: 0.6934 - loss: 2.7649 - return_1h_loss: 0.0588 - return_1h_mae: 0.1765 - return_1h_mse: 0.0588 - return_24h_loss: 0.0663 - return_24h_mae: 0.1870 - return_24h_mse: 0.0663 - return_4h_loss: 0.0541 - return_4h_mae: 0.1661 - return_4h_mse: 0.0541 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7237 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.8066 - val_loss: 2.8436 - val_return_1h_loss: 0.0032 - val_return_1h_mae: 0.0477 - val_return_1h_mse: 0.0033 - val_return_24h_loss: 0.0070 - val_return_24h_mae: 0.0792 - val_return_24h_mse: 0.0071 - val_return_4h_loss: 0.0147 - val_return_4h_mae: 0.1033 - val_return_4h_mse: 0.0130 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5364 - direction_1h_binary_accuracy: 0.5364 - direction_1h_loss: 0.7012 - direction_4h_accuracy: 0.5786 - direction_4h_binary_accuracy: 0.5786 - direction_4h_loss: 0.6833 - loss: 2.7109 - return_1h_loss: 0.0429 - return_1h_mae: 0.1521 - return_1h_mse: 0.0429 - return_24h_loss: 0.0529 - return_24h_mae: 0.1665 - return_24h_mse: 0.0529 - return_4h_loss: 0.0399 - return_4h_mae: 0.1444 - return_4h_mse: 0.0399\n",
            "Epoch 12: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5365 - direction_1h_binary_accuracy: 0.5365 - direction_1h_loss: 0.7011 - direction_4h_accuracy: 0.5788 - direction_4h_binary_accuracy: 0.5788 - direction_4h_loss: 0.6832 - loss: 2.7104 - return_1h_loss: 0.0428 - return_1h_mae: 0.1521 - return_1h_mse: 0.0428 - return_24h_loss: 0.0529 - return_24h_mae: 0.1665 - return_24h_mse: 0.0529 - return_4h_loss: 0.0398 - return_4h_mae: 0.1443 - return_4h_mse: 0.0398 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7226 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.8242 - val_loss: 2.8706 - val_return_1h_loss: 0.0074 - val_return_1h_mae: 0.0786 - val_return_1h_mse: 0.0071 - val_return_24h_loss: 8.6527e-04 - val_return_24h_mae: 0.0250 - val_return_24h_mse: 9.2591e-04 - val_return_4h_loss: 0.0133 - val_return_4h_mae: 0.1017 - val_return_4h_mse: 0.0119 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5488 - direction_1h_binary_accuracy: 0.5488 - direction_1h_loss: 0.6952 - direction_4h_accuracy: 0.5763 - direction_4h_binary_accuracy: 0.5763 - direction_4h_loss: 0.6877 - loss: 2.6915 - return_1h_loss: 0.0390 - return_1h_mae: 0.1417 - return_1h_mse: 0.0390 - return_24h_loss: 0.0468 - return_24h_mae: 0.1529 - return_24h_mse: 0.0467 - return_4h_loss: 0.0329 - return_4h_mae: 0.1310 - return_4h_mse: 0.0329\n",
            "Epoch 13: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5489 - direction_1h_binary_accuracy: 0.5489 - direction_1h_loss: 0.6952 - direction_4h_accuracy: 0.5765 - direction_4h_binary_accuracy: 0.5765 - direction_4h_loss: 0.6874 - loss: 2.6908 - return_1h_loss: 0.0389 - return_1h_mae: 0.1417 - return_1h_mse: 0.0390 - return_24h_loss: 0.0467 - return_24h_mae: 0.1529 - return_24h_mse: 0.0467 - return_4h_loss: 0.0329 - return_4h_mae: 0.1310 - return_4h_mse: 0.0329 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7226 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.8188 - val_loss: 2.8637 - val_return_1h_loss: 0.0072 - val_return_1h_mae: 0.0741 - val_return_1h_mse: 0.0067 - val_return_24h_loss: 0.0021 - val_return_24h_mae: 0.0418 - val_return_24h_mse: 0.0022 - val_return_4h_loss: 0.0113 - val_return_4h_mae: 0.0943 - val_return_4h_mse: 0.0101 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5420 - direction_1h_binary_accuracy: 0.5420 - direction_1h_loss: 0.6987 - direction_4h_accuracy: 0.5775 - direction_4h_binary_accuracy: 0.5775 - direction_4h_loss: 0.6762 - loss: 2.6666 - return_1h_loss: 0.0325 - return_1h_mae: 0.1319 - return_1h_mse: 0.0325 - return_24h_loss: 0.0409 - return_24h_mae: 0.1461 - return_24h_mse: 0.0409 - return_4h_loss: 0.0279 - return_4h_mae: 0.1218 - return_4h_mse: 0.0279\n",
            "Epoch 14: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5418 - direction_1h_binary_accuracy: 0.5418 - direction_1h_loss: 0.6988 - direction_4h_accuracy: 0.5779 - direction_4h_binary_accuracy: 0.5779 - direction_4h_loss: 0.6760 - loss: 2.6662 - return_1h_loss: 0.0325 - return_1h_mae: 0.1319 - return_1h_mse: 0.0325 - return_24h_loss: 0.0408 - return_24h_mae: 0.1461 - return_24h_mse: 0.0408 - return_4h_loss: 0.0278 - return_4h_mae: 0.1218 - return_4h_mse: 0.0278 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7177 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.8199 - val_loss: 2.8505 - val_return_1h_loss: 0.0038 - val_return_1h_mae: 0.0507 - val_return_1h_mse: 0.0035 - val_return_24h_loss: 0.0033 - val_return_24h_mae: 0.0537 - val_return_24h_mse: 0.0035 - val_return_4h_loss: 0.0119 - val_return_4h_mae: 0.0967 - val_return_4h_mse: 0.0110 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5305 - direction_1h_binary_accuracy: 0.5305 - direction_1h_loss: 0.6960 - direction_4h_accuracy: 0.6012 - direction_4h_binary_accuracy: 0.6012 - direction_4h_loss: 0.6692 - loss: 2.6361 - return_1h_loss: 0.0261 - return_1h_mae: 0.1196 - return_1h_mse: 0.0261 - return_24h_loss: 0.0354 - return_24h_mae: 0.1359 - return_24h_mse: 0.0354 - return_4h_loss: 0.0225 - return_4h_mae: 0.1094 - return_4h_mse: 0.0225\n",
            "Epoch 15: val_loss did not improve from 2.76060\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5307 - direction_1h_binary_accuracy: 0.5307 - direction_1h_loss: 0.6960 - direction_4h_accuracy: 0.6015 - direction_4h_binary_accuracy: 0.6015 - direction_4h_loss: 0.6689 - loss: 2.6355 - return_1h_loss: 0.0261 - return_1h_mae: 0.1196 - return_1h_mse: 0.0261 - return_24h_loss: 0.0354 - return_24h_mae: 0.1358 - return_24h_mse: 0.0354 - return_4h_loss: 0.0225 - return_4h_mae: 0.1094 - return_4h_mse: 0.0225 - val_direction_1h_accuracy: 0.4757 - val_direction_1h_binary_accuracy: 0.4757 - val_direction_1h_loss: 0.7163 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.8000 - val_loss: 2.8109 - val_return_1h_loss: 0.0041 - val_return_1h_mae: 0.0516 - val_return_1h_mse: 0.0037 - val_return_24h_loss: 0.0024 - val_return_24h_mae: 0.0447 - val_return_24h_mse: 0.0026 - val_return_4h_loss: 0.0074 - val_return_4h_mae: 0.0734 - val_return_4h_mse: 0.0067 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5486 - direction_1h_binary_accuracy: 0.5486 - direction_1h_loss: 0.6933 - direction_4h_accuracy: 0.5928 - direction_4h_binary_accuracy: 0.5928 - direction_4h_loss: 0.6661 - loss: 2.6192 - return_1h_loss: 0.0241 - return_1h_mae: 0.1133 - return_1h_mse: 0.0241 - return_24h_loss: 0.0296 - return_24h_mae: 0.1233 - return_24h_mse: 0.0296 - return_4h_loss: 0.0208 - return_4h_mae: 0.1047 - return_4h_mse: 0.0208\n",
            "Epoch 16: val_loss improved from 2.76060 to 2.71220, saving model to best_trading_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5487 - direction_1h_binary_accuracy: 0.5487 - direction_1h_loss: 0.6934 - direction_4h_accuracy: 0.5931 - direction_4h_binary_accuracy: 0.5931 - direction_4h_loss: 0.6659 - loss: 2.6189 - return_1h_loss: 0.0241 - return_1h_mae: 0.1133 - return_1h_mse: 0.0241 - return_24h_loss: 0.0296 - return_24h_mae: 0.1233 - return_24h_mse: 0.0296 - return_4h_loss: 0.0208 - return_4h_mae: 0.1046 - return_4h_mse: 0.0208 - val_direction_1h_accuracy: 0.4774 - val_direction_1h_binary_accuracy: 0.4774 - val_direction_1h_loss: 0.7062 - val_direction_4h_accuracy: 0.4617 - val_direction_4h_binary_accuracy: 0.4617 - val_direction_4h_loss: 0.7499 - val_loss: 2.7122 - val_return_1h_loss: 0.0013 - val_return_1h_mae: 0.0286 - val_return_1h_mse: 0.0012 - val_return_24h_loss: 0.0020 - val_return_24h_mae: 0.0410 - val_return_24h_mse: 0.0021 - val_return_4h_loss: 0.0033 - val_return_4h_mae: 0.0453 - val_return_4h_mse: 0.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5549 - direction_1h_binary_accuracy: 0.5549 - direction_1h_loss: 0.6895 - direction_4h_accuracy: 0.6052 - direction_4h_binary_accuracy: 0.6052 - direction_4h_loss: 0.6650 - loss: 2.5993 - return_1h_loss: 0.0194 - return_1h_mae: 0.1019 - return_1h_mse: 0.0194 - return_24h_loss: 0.0238 - return_24h_mae: 0.1114 - return_24h_mse: 0.0238 - return_4h_loss: 0.0181 - return_4h_mae: 0.0975 - return_4h_mse: 0.0181\n",
            "Epoch 17: val_loss improved from 2.71220 to 2.67820, saving model to best_trading_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5548 - direction_1h_binary_accuracy: 0.5548 - direction_1h_loss: 0.6895 - direction_4h_accuracy: 0.6053 - direction_4h_binary_accuracy: 0.6053 - direction_4h_loss: 0.6649 - loss: 2.5990 - return_1h_loss: 0.0194 - return_1h_mae: 0.1019 - return_1h_mse: 0.0194 - return_24h_loss: 0.0237 - return_24h_mae: 0.1114 - return_24h_mse: 0.0237 - return_4h_loss: 0.0181 - return_4h_mae: 0.0974 - return_4h_mse: 0.0181 - val_direction_1h_accuracy: 0.4791 - val_direction_1h_binary_accuracy: 0.4791 - val_direction_1h_loss: 0.7027 - val_direction_4h_accuracy: 0.4635 - val_direction_4h_binary_accuracy: 0.4635 - val_direction_4h_loss: 0.7349 - val_loss: 2.6782 - val_return_1h_loss: 6.7663e-04 - val_return_1h_mae: 0.0217 - val_return_1h_mse: 7.4436e-04 - val_return_24h_loss: 0.0012 - val_return_24h_mae: 0.0295 - val_return_24h_mse: 0.0013 - val_return_4h_loss: 0.0014 - val_return_4h_mae: 0.0287 - val_return_4h_mse: 0.0013 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5626 - direction_1h_binary_accuracy: 0.5626 - direction_1h_loss: 0.6827 - direction_4h_accuracy: 0.6170 - direction_4h_binary_accuracy: 0.6170 - direction_4h_loss: 0.6513 - loss: 2.5563 - return_1h_loss: 0.0166 - return_1h_mae: 0.0928 - return_1h_mse: 0.0166 - return_24h_loss: 0.0204 - return_24h_mae: 0.1040 - return_24h_mse: 0.0204 - return_4h_loss: 0.0140 - return_4h_mae: 0.0857 - return_4h_mse: 0.0140\n",
            "Epoch 18: val_loss did not improve from 2.67820\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5626 - direction_1h_binary_accuracy: 0.5626 - direction_1h_loss: 0.6828 - direction_4h_accuracy: 0.6174 - direction_4h_binary_accuracy: 0.6174 - direction_4h_loss: 0.6511 - loss: 2.5562 - return_1h_loss: 0.0165 - return_1h_mae: 0.0928 - return_1h_mse: 0.0165 - return_24h_loss: 0.0204 - return_24h_mae: 0.1040 - return_24h_mse: 0.0204 - return_4h_loss: 0.0140 - return_4h_mae: 0.0857 - return_4h_mse: 0.0140 - val_direction_1h_accuracy: 0.4843 - val_direction_1h_binary_accuracy: 0.4843 - val_direction_1h_loss: 0.7066 - val_direction_4h_accuracy: 0.4635 - val_direction_4h_binary_accuracy: 0.4635 - val_direction_4h_loss: 0.7405 - val_loss: 2.6912 - val_return_1h_loss: 6.4603e-04 - val_return_1h_mae: 0.0212 - val_return_1h_mse: 7.1256e-04 - val_return_24h_loss: 0.0011 - val_return_24h_mae: 0.0270 - val_return_24h_mse: 0.0011 - val_return_4h_loss: 8.3689e-04 - val_return_4h_mae: 0.0223 - val_return_4h_mse: 8.4445e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5663 - direction_1h_binary_accuracy: 0.5663 - direction_1h_loss: 0.6844 - direction_4h_accuracy: 0.6328 - direction_4h_binary_accuracy: 0.6328 - direction_4h_loss: 0.6454 - loss: 2.5444 - return_1h_loss: 0.0134 - return_1h_mae: 0.0855 - return_1h_mse: 0.0134 - return_24h_loss: 0.0171 - return_24h_mae: 0.0941 - return_24h_mse: 0.0171 - return_4h_loss: 0.0125 - return_4h_mae: 0.0800 - return_4h_mse: 0.0125\n",
            "Epoch 19: val_loss improved from 2.67820 to 2.63762, saving model to best_trading_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5664 - direction_1h_binary_accuracy: 0.5664 - direction_1h_loss: 0.6843 - direction_4h_accuracy: 0.6331 - direction_4h_binary_accuracy: 0.6331 - direction_4h_loss: 0.6452 - loss: 2.5440 - return_1h_loss: 0.0134 - return_1h_mae: 0.0855 - return_1h_mse: 0.0134 - return_24h_loss: 0.0171 - return_24h_mae: 0.0941 - return_24h_mse: 0.0171 - return_4h_loss: 0.0125 - return_4h_mae: 0.0800 - return_4h_mse: 0.0125 - val_direction_1h_accuracy: 0.5061 - val_direction_1h_binary_accuracy: 0.5061 - val_direction_1h_loss: 0.6995 - val_direction_4h_accuracy: 0.4852 - val_direction_4h_binary_accuracy: 0.4852 - val_direction_4h_loss: 0.7135 - val_loss: 2.6376 - val_return_1h_loss: 6.8592e-04 - val_return_1h_mae: 0.0195 - val_return_1h_mse: 6.0719e-04 - val_return_24h_loss: 9.1878e-04 - val_return_24h_mae: 0.0259 - val_return_24h_mse: 9.8024e-04 - val_return_4h_loss: 9.1818e-04 - val_return_4h_mae: 0.0247 - val_return_4h_mse: 9.9599e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5643 - direction_1h_binary_accuracy: 0.5643 - direction_1h_loss: 0.6843 - direction_4h_accuracy: 0.6243 - direction_4h_binary_accuracy: 0.6243 - direction_4h_loss: 0.6409 - loss: 2.5319 - return_1h_loss: 0.0120 - return_1h_mae: 0.0806 - return_1h_mse: 0.0120 - return_24h_loss: 0.0140 - return_24h_mae: 0.0864 - return_24h_mse: 0.0140 - return_4h_loss: 0.0100 - return_4h_mae: 0.0720 - return_4h_mse: 0.0100\n",
            "Epoch 20: val_loss improved from 2.63762 to 2.62667, saving model to best_trading_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5644 - direction_1h_binary_accuracy: 0.5644 - direction_1h_loss: 0.6843 - direction_4h_accuracy: 0.6247 - direction_4h_binary_accuracy: 0.6247 - direction_4h_loss: 0.6407 - loss: 2.5315 - return_1h_loss: 0.0120 - return_1h_mae: 0.0805 - return_1h_mse: 0.0120 - return_24h_loss: 0.0141 - return_24h_mae: 0.0864 - return_24h_mse: 0.0141 - return_4h_loss: 0.0100 - return_4h_mae: 0.0720 - return_4h_mse: 0.0100 - val_direction_1h_accuracy: 0.5078 - val_direction_1h_binary_accuracy: 0.5078 - val_direction_1h_loss: 0.6996 - val_direction_4h_accuracy: 0.4757 - val_direction_4h_binary_accuracy: 0.4757 - val_direction_4h_loss: 0.7061 - val_loss: 2.6267 - val_return_1h_loss: 6.3638e-04 - val_return_1h_mae: 0.0184 - val_return_1h_mse: 5.4749e-04 - val_return_24h_loss: 7.2525e-04 - val_return_24h_mae: 0.0215 - val_return_24h_mse: 7.2724e-04 - val_return_4h_loss: 5.3815e-04 - val_return_4h_mae: 0.0184 - val_return_4h_mse: 5.7142e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - direction_1h_accuracy: 0.5728 - direction_1h_binary_accuracy: 0.5728 - direction_1h_loss: 0.6776 - direction_4h_accuracy: 0.6519 - direction_4h_binary_accuracy: 0.6519 - direction_4h_loss: 0.6267 - loss: 2.4919 - return_1h_loss: 0.0099 - return_1h_mae: 0.0727 - return_1h_mse: 0.0099 - return_24h_loss: 0.0125 - return_24h_mae: 0.0800 - return_24h_mse: 0.0125 - return_4h_loss: 0.0079 - return_4h_mae: 0.0648 - return_4h_mse: 0.0079\n",
            "Epoch 21: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - direction_1h_accuracy: 0.5727 - direction_1h_binary_accuracy: 0.5727 - direction_1h_loss: 0.6776 - direction_4h_accuracy: 0.6517 - direction_4h_binary_accuracy: 0.6517 - direction_4h_loss: 0.6268 - loss: 2.4920 - return_1h_loss: 0.0099 - return_1h_mae: 0.0726 - return_1h_mse: 0.0099 - return_24h_loss: 0.0124 - return_24h_mae: 0.0800 - return_24h_mse: 0.0124 - return_4h_loss: 0.0079 - return_4h_mae: 0.0648 - return_4h_mse: 0.0079 - val_direction_1h_accuracy: 0.5165 - val_direction_1h_binary_accuracy: 0.5165 - val_direction_1h_loss: 0.7043 - val_direction_4h_accuracy: 0.5252 - val_direction_4h_binary_accuracy: 0.5252 - val_direction_4h_loss: 0.7028 - val_loss: 2.6347 - val_return_1h_loss: 6.5280e-04 - val_return_1h_mae: 0.0188 - val_return_1h_mse: 5.5861e-04 - val_return_24h_loss: 0.0012 - val_return_24h_mae: 0.0272 - val_return_24h_mse: 0.0012 - val_return_4h_loss: 5.9540e-04 - val_return_4h_mae: 0.0195 - val_return_4h_mse: 6.1716e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - direction_1h_accuracy: 0.5623 - direction_1h_binary_accuracy: 0.5623 - direction_1h_loss: 0.6819 - direction_4h_accuracy: 0.6460 - direction_4h_binary_accuracy: 0.6460 - direction_4h_loss: 0.6299 - loss: 2.5010 - return_1h_loss: 0.0082 - return_1h_mae: 0.0659 - return_1h_mse: 0.0082 - return_24h_loss: 0.0092 - return_24h_mae: 0.0697 - return_24h_mse: 0.0092 - return_4h_loss: 0.0070 - return_4h_mae: 0.0606 - return_4h_mse: 0.0070\n",
            "Epoch 22: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - direction_1h_accuracy: 0.5624 - direction_1h_binary_accuracy: 0.5624 - direction_1h_loss: 0.6818 - direction_4h_accuracy: 0.6460 - direction_4h_binary_accuracy: 0.6460 - direction_4h_loss: 0.6298 - loss: 2.5006 - return_1h_loss: 0.0082 - return_1h_mae: 0.0659 - return_1h_mse: 0.0082 - return_24h_loss: 0.0091 - return_24h_mae: 0.0697 - return_24h_mse: 0.0092 - return_4h_loss: 0.0070 - return_4h_mae: 0.0605 - return_4h_mse: 0.0070 - val_direction_1h_accuracy: 0.5139 - val_direction_1h_binary_accuracy: 0.5139 - val_direction_1h_loss: 0.7153 - val_direction_4h_accuracy: 0.5061 - val_direction_4h_binary_accuracy: 0.5061 - val_direction_4h_loss: 0.7058 - val_loss: 2.6586 - val_return_1h_loss: 6.1408e-04 - val_return_1h_mae: 0.0178 - val_return_1h_mse: 5.2298e-04 - val_return_24h_loss: 0.0014 - val_return_24h_mae: 0.0306 - val_return_24h_mse: 0.0014 - val_return_4h_loss: 4.2252e-04 - val_return_4h_mae: 0.0177 - val_return_4h_mse: 4.2593e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - direction_1h_accuracy: 0.5660 - direction_1h_binary_accuracy: 0.5660 - direction_1h_loss: 0.6823 - direction_4h_accuracy: 0.6454 - direction_4h_binary_accuracy: 0.6454 - direction_4h_loss: 0.6302 - loss: 2.4984 - return_1h_loss: 0.0066 - return_1h_mae: 0.0591 - return_1h_mse: 0.0066 - return_24h_loss: 0.0079 - return_24h_mae: 0.0645 - return_24h_mse: 0.0079 - return_4h_loss: 0.0057 - return_4h_mae: 0.0546 - return_4h_mse: 0.0057\n",
            "Epoch 23: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - direction_1h_accuracy: 0.5662 - direction_1h_binary_accuracy: 0.5662 - direction_1h_loss: 0.6822 - direction_4h_accuracy: 0.6456 - direction_4h_binary_accuracy: 0.6456 - direction_4h_loss: 0.6300 - loss: 2.4980 - return_1h_loss: 0.0066 - return_1h_mae: 0.0590 - return_1h_mse: 0.0066 - return_24h_loss: 0.0078 - return_24h_mae: 0.0645 - return_24h_mse: 0.0078 - return_4h_loss: 0.0057 - return_4h_mae: 0.0546 - return_4h_mse: 0.0057 - val_direction_1h_accuracy: 0.5209 - val_direction_1h_binary_accuracy: 0.5209 - val_direction_1h_loss: 0.7331 - val_direction_4h_accuracy: 0.5130 - val_direction_4h_binary_accuracy: 0.5130 - val_direction_4h_loss: 0.7270 - val_loss: 2.7217 - val_return_1h_loss: 0.0017 - val_return_1h_mae: 0.0312 - val_return_1h_mse: 0.0014 - val_return_24h_loss: 0.0012 - val_return_24h_mae: 0.0274 - val_return_24h_mse: 0.0012 - val_return_4h_loss: 4.4465e-04 - val_return_4h_mae: 0.0178 - val_return_4h_mse: 4.6520e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5726 - direction_1h_binary_accuracy: 0.5726 - direction_1h_loss: 0.6806 - direction_4h_accuracy: 0.6504 - direction_4h_binary_accuracy: 0.6504 - direction_4h_loss: 0.6262 - loss: 2.4852 - return_1h_loss: 0.0051 - return_1h_mae: 0.0523 - return_1h_mse: 0.0051 - return_24h_loss: 0.0067 - return_24h_mae: 0.0577 - return_24h_mse: 0.0067 - return_4h_loss: 0.0043 - return_4h_mae: 0.0474 - return_4h_mse: 0.0043\n",
            "Epoch 24: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - direction_1h_accuracy: 0.5728 - direction_1h_binary_accuracy: 0.5728 - direction_1h_loss: 0.6805 - direction_4h_accuracy: 0.6507 - direction_4h_binary_accuracy: 0.6507 - direction_4h_loss: 0.6259 - loss: 2.4846 - return_1h_loss: 0.0051 - return_1h_mae: 0.0523 - return_1h_mse: 0.0051 - return_24h_loss: 0.0067 - return_24h_mae: 0.0577 - return_24h_mse: 0.0067 - return_4h_loss: 0.0043 - return_4h_mae: 0.0474 - return_4h_mse: 0.0043 - val_direction_1h_accuracy: 0.5278 - val_direction_1h_binary_accuracy: 0.5278 - val_direction_1h_loss: 0.7491 - val_direction_4h_accuracy: 0.5157 - val_direction_4h_binary_accuracy: 0.5157 - val_direction_4h_loss: 0.7503 - val_loss: 2.7788 - val_return_1h_loss: 5.2064e-04 - val_return_1h_mae: 0.0169 - val_return_1h_mse: 4.3578e-04 - val_return_24h_loss: 5.2863e-04 - val_return_24h_mae: 0.0183 - val_return_24h_mse: 5.4706e-04 - val_return_4h_loss: 5.7434e-04 - val_return_4h_mae: 0.0205 - val_return_4h_mse: 5.9473e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5876 - direction_1h_binary_accuracy: 0.5876 - direction_1h_loss: 0.6736 - direction_4h_accuracy: 0.6605 - direction_4h_binary_accuracy: 0.6605 - direction_4h_loss: 0.6154 - loss: 2.4525 - return_1h_loss: 0.0042 - return_1h_mae: 0.0473 - return_1h_mse: 0.0042 - return_24h_loss: 0.0053 - return_24h_mae: 0.0514 - return_24h_mse: 0.0053 - return_4h_loss: 0.0036 - return_4h_mae: 0.0429 - return_4h_mse: 0.0036\n",
            "Epoch 25: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5876 - direction_1h_binary_accuracy: 0.5876 - direction_1h_loss: 0.6736 - direction_4h_accuracy: 0.6606 - direction_4h_binary_accuracy: 0.6606 - direction_4h_loss: 0.6152 - loss: 2.4523 - return_1h_loss: 0.0042 - return_1h_mae: 0.0473 - return_1h_mse: 0.0042 - return_24h_loss: 0.0053 - return_24h_mae: 0.0514 - return_24h_mse: 0.0053 - return_4h_loss: 0.0036 - return_4h_mae: 0.0429 - return_4h_mse: 0.0036 - val_direction_1h_accuracy: 0.5296 - val_direction_1h_binary_accuracy: 0.5296 - val_direction_1h_loss: 0.7306 - val_direction_4h_accuracy: 0.5391 - val_direction_4h_binary_accuracy: 0.5391 - val_direction_4h_loss: 0.7273 - val_loss: 2.7156 - val_return_1h_loss: 5.6799e-04 - val_return_1h_mae: 0.0182 - val_return_1h_mse: 4.8009e-04 - val_return_24h_loss: 0.0013 - val_return_24h_mae: 0.0302 - val_return_24h_mse: 0.0013 - val_return_4h_loss: 3.7991e-04 - val_return_4h_mae: 0.0163 - val_return_4h_mse: 3.8966e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5792 - direction_1h_binary_accuracy: 0.5792 - direction_1h_loss: 0.6737 - direction_4h_accuracy: 0.6589 - direction_4h_binary_accuracy: 0.6589 - direction_4h_loss: 0.6135 - loss: 2.4476 - return_1h_loss: 0.0033 - return_1h_mae: 0.0414 - return_1h_mse: 0.0033 - return_24h_loss: 0.0044 - return_24h_mae: 0.0471 - return_24h_mse: 0.0044 - return_4h_loss: 0.0027 - return_4h_mae: 0.0379 - return_4h_mse: 0.0027\n",
            "Epoch 26: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5794 - direction_1h_binary_accuracy: 0.5794 - direction_1h_loss: 0.6736 - direction_4h_accuracy: 0.6591 - direction_4h_binary_accuracy: 0.6591 - direction_4h_loss: 0.6132 - loss: 2.4471 - return_1h_loss: 0.0032 - return_1h_mae: 0.0414 - return_1h_mse: 0.0032 - return_24h_loss: 0.0044 - return_24h_mae: 0.0471 - return_24h_mse: 0.0044 - return_4h_loss: 0.0027 - return_4h_mae: 0.0379 - return_4h_mse: 0.0027 - val_direction_1h_accuracy: 0.5226 - val_direction_1h_binary_accuracy: 0.5226 - val_direction_1h_loss: 0.8052 - val_direction_4h_accuracy: 0.5339 - val_direction_4h_binary_accuracy: 0.5339 - val_direction_4h_loss: 0.8204 - val_loss: 2.9887 - val_return_1h_loss: 8.8869e-04 - val_return_1h_mae: 0.0222 - val_return_1h_mse: 7.2220e-04 - val_return_24h_loss: 3.8612e-04 - val_return_24h_mae: 0.0170 - val_return_24h_mse: 4.0150e-04 - val_return_4h_loss: 2.6619e-04 - val_return_4h_mae: 0.0137 - val_return_4h_mse: 2.6890e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5872 - direction_1h_binary_accuracy: 0.5872 - direction_1h_loss: 0.6701 - direction_4h_accuracy: 0.6714 - direction_4h_binary_accuracy: 0.6714 - direction_4h_loss: 0.6043 - loss: 2.4245 - return_1h_loss: 0.0025 - return_1h_mae: 0.0369 - return_1h_mse: 0.0025 - return_24h_loss: 0.0034 - return_24h_mae: 0.0421 - return_24h_mse: 0.0034 - return_4h_loss: 0.0021 - return_4h_mae: 0.0330 - return_4h_mse: 0.0021\n",
            "Epoch 27: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5872 - direction_1h_binary_accuracy: 0.5872 - direction_1h_loss: 0.6701 - direction_4h_accuracy: 0.6717 - direction_4h_binary_accuracy: 0.6717 - direction_4h_loss: 0.6040 - loss: 2.4240 - return_1h_loss: 0.0025 - return_1h_mae: 0.0369 - return_1h_mse: 0.0025 - return_24h_loss: 0.0034 - return_24h_mae: 0.0421 - return_24h_mse: 0.0034 - return_4h_loss: 0.0021 - return_4h_mae: 0.0330 - return_4h_mse: 0.0021 - val_direction_1h_accuracy: 0.5209 - val_direction_1h_binary_accuracy: 0.5209 - val_direction_1h_loss: 0.7957 - val_direction_4h_accuracy: 0.5374 - val_direction_4h_binary_accuracy: 0.5374 - val_direction_4h_loss: 0.8376 - val_loss: 2.9946 - val_return_1h_loss: 9.0211e-04 - val_return_1h_mae: 0.0228 - val_return_1h_mse: 7.8839e-04 - val_return_24h_loss: 0.0015 - val_return_24h_mae: 0.0340 - val_return_24h_mse: 0.0014 - val_return_4h_loss: 2.4432e-04 - val_return_4h_mae: 0.0130 - val_return_4h_mse: 2.3521e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5896 - direction_1h_binary_accuracy: 0.5896 - direction_1h_loss: 0.6728 - direction_4h_accuracy: 0.6739 - direction_4h_binary_accuracy: 0.6739 - direction_4h_loss: 0.6006 - loss: 2.4232 - return_1h_loss: 0.0021 - return_1h_mae: 0.0335 - return_1h_mse: 0.0021 - return_24h_loss: 0.0030 - return_24h_mae: 0.0381 - return_24h_mse: 0.0030 - return_4h_loss: 0.0017 - return_4h_mae: 0.0300 - return_4h_mse: 0.0017\n",
            "Epoch 28: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5895 - direction_1h_binary_accuracy: 0.5895 - direction_1h_loss: 0.6727 - direction_4h_accuracy: 0.6739 - direction_4h_binary_accuracy: 0.6739 - direction_4h_loss: 0.6006 - loss: 2.4231 - return_1h_loss: 0.0021 - return_1h_mae: 0.0335 - return_1h_mse: 0.0021 - return_24h_loss: 0.0030 - return_24h_mae: 0.0381 - return_24h_mse: 0.0030 - return_4h_loss: 0.0017 - return_4h_mae: 0.0300 - return_4h_mse: 0.0017 - val_direction_1h_accuracy: 0.5209 - val_direction_1h_binary_accuracy: 0.5209 - val_direction_1h_loss: 0.8036 - val_direction_4h_accuracy: 0.5252 - val_direction_4h_binary_accuracy: 0.5252 - val_direction_4h_loss: 0.8383 - val_loss: 3.0053 - val_return_1h_loss: 3.3742e-04 - val_return_1h_mae: 0.0133 - val_return_1h_mse: 2.6963e-04 - val_return_24h_loss: 0.0024 - val_return_24h_mae: 0.0450 - val_return_24h_mse: 0.0023 - val_return_4h_loss: 1.9543e-04 - val_return_4h_mae: 0.0113 - val_return_4h_mse: 1.8301e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5824 - direction_1h_binary_accuracy: 0.5824 - direction_1h_loss: 0.6760 - direction_4h_accuracy: 0.6674 - direction_4h_binary_accuracy: 0.6674 - direction_4h_loss: 0.6030 - loss: 2.4319 - return_1h_loss: 0.0016 - return_1h_mae: 0.0291 - return_1h_mse: 0.0016 - return_24h_loss: 0.0022 - return_24h_mae: 0.0336 - return_24h_mse: 0.0022 - return_4h_loss: 0.0014 - return_4h_mae: 0.0268 - return_4h_mse: 0.0014\n",
            "Epoch 29: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - direction_1h_accuracy: 0.5825 - direction_1h_binary_accuracy: 0.5825 - direction_1h_loss: 0.6759 - direction_4h_accuracy: 0.6675 - direction_4h_binary_accuracy: 0.6675 - direction_4h_loss: 0.6030 - loss: 2.4317 - return_1h_loss: 0.0016 - return_1h_mae: 0.0291 - return_1h_mse: 0.0016 - return_24h_loss: 0.0022 - return_24h_mae: 0.0336 - return_24h_mse: 0.0022 - return_4h_loss: 0.0014 - return_4h_mae: 0.0268 - return_4h_mse: 0.0014 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 0.9962 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.1736 - val_loss: 3.8820 - val_return_1h_loss: 5.7918e-04 - val_return_1h_mae: 0.0212 - val_return_1h_mse: 5.1433e-04 - val_return_24h_loss: 0.0015 - val_return_24h_mae: 0.0354 - val_return_24h_mse: 0.0014 - val_return_4h_loss: 6.1944e-05 - val_return_4h_mae: 0.0061 - val_return_4h_mse: 5.9706e-05 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5902 - direction_1h_binary_accuracy: 0.5902 - direction_1h_loss: 0.6702 - direction_4h_accuracy: 0.6790 - direction_4h_binary_accuracy: 0.6790 - direction_4h_loss: 0.5920 - loss: 2.4024 - return_1h_loss: 0.0013 - return_1h_mae: 0.0259 - return_1h_mse: 0.0013 - return_24h_loss: 0.0018 - return_24h_mae: 0.0303 - return_24h_mse: 0.0018 - return_4h_loss: 9.7584e-04 - return_4h_mae: 0.0229 - return_4h_mse: 9.7582e-04\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 30: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5902 - direction_1h_binary_accuracy: 0.5902 - direction_1h_loss: 0.6702 - direction_4h_accuracy: 0.6790 - direction_4h_binary_accuracy: 0.6790 - direction_4h_loss: 0.5919 - loss: 2.4023 - return_1h_loss: 0.0013 - return_1h_mae: 0.0259 - return_1h_mse: 0.0013 - return_24h_loss: 0.0018 - return_24h_mae: 0.0303 - return_24h_mse: 0.0018 - return_4h_loss: 9.7543e-04 - return_4h_mae: 0.0229 - return_4h_mse: 9.7540e-04 - val_direction_1h_accuracy: 0.5104 - val_direction_1h_binary_accuracy: 0.5104 - val_direction_1h_loss: 0.7246 - val_direction_4h_accuracy: 0.4748 - val_direction_4h_binary_accuracy: 0.4748 - val_direction_4h_loss: 0.8136 - val_loss: 2.8047 - val_return_1h_loss: 1.0983e-04 - val_return_1h_mae: 0.0086 - val_return_1h_mse: 1.0153e-04 - val_return_24h_loss: 3.8722e-04 - val_return_24h_mae: 0.0163 - val_return_24h_mse: 3.5064e-04 - val_return_4h_loss: 4.0575e-04 - val_return_4h_mae: 0.0150 - val_return_4h_mse: 3.3775e-04 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.5904 - direction_1h_binary_accuracy: 0.5904 - direction_1h_loss: 0.6674 - direction_4h_accuracy: 0.6720 - direction_4h_binary_accuracy: 0.6720 - direction_4h_loss: 0.5916 - loss: 2.3958 - return_1h_loss: 0.0011 - return_1h_mae: 0.0238 - return_1h_mse: 0.0011 - return_24h_loss: 0.0015 - return_24h_mae: 0.0274 - return_24h_mse: 0.0015 - return_4h_loss: 8.3932e-04 - return_4h_mae: 0.0210 - return_4h_mse: 8.3943e-04\n",
            "Epoch 31: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.5906 - direction_1h_binary_accuracy: 0.5906 - direction_1h_loss: 0.6673 - direction_4h_accuracy: 0.6723 - direction_4h_binary_accuracy: 0.6723 - direction_4h_loss: 0.5913 - loss: 2.3951 - return_1h_loss: 0.0011 - return_1h_mae: 0.0238 - return_1h_mse: 0.0011 - return_24h_loss: 0.0015 - return_24h_mae: 0.0274 - return_24h_mse: 0.0015 - return_4h_loss: 8.3835e-04 - return_4h_mae: 0.0210 - return_4h_mse: 8.3857e-04 - val_direction_1h_accuracy: 0.5226 - val_direction_1h_binary_accuracy: 0.5226 - val_direction_1h_loss: 0.7884 - val_direction_4h_accuracy: 0.5313 - val_direction_4h_binary_accuracy: 0.5313 - val_direction_4h_loss: 0.8026 - val_loss: 2.9274 - val_return_1h_loss: 1.7102e-04 - val_return_1h_mae: 0.0108 - val_return_1h_mse: 1.6422e-04 - val_return_24h_loss: 7.1944e-04 - val_return_24h_mae: 0.0226 - val_return_24h_mse: 6.3372e-04 - val_return_4h_loss: 1.7514e-04 - val_return_4h_mae: 0.0090 - val_return_4h_mse: 1.4546e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6040 - direction_1h_binary_accuracy: 0.6040 - direction_1h_loss: 0.6639 - direction_4h_accuracy: 0.7083 - direction_4h_binary_accuracy: 0.7083 - direction_4h_loss: 0.5639 - loss: 2.3466 - return_1h_loss: 9.0164e-04 - return_1h_mae: 0.0217 - return_1h_mse: 9.0164e-04 - return_24h_loss: 0.0012 - return_24h_mae: 0.0252 - return_24h_mse: 0.0012 - return_4h_loss: 6.7874e-04 - return_4h_mae: 0.0188 - return_4h_mse: 6.7873e-04\n",
            "Epoch 32: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6040 - direction_1h_binary_accuracy: 0.6040 - direction_1h_loss: 0.6639 - direction_4h_accuracy: 0.7084 - direction_4h_binary_accuracy: 0.7084 - direction_4h_loss: 0.5636 - loss: 2.3461 - return_1h_loss: 9.0134e-04 - return_1h_mae: 0.0217 - return_1h_mse: 9.0135e-04 - return_24h_loss: 0.0012 - return_24h_mae: 0.0252 - return_24h_mse: 0.0012 - return_4h_loss: 6.7896e-04 - return_4h_mae: 0.0188 - return_4h_mse: 6.7893e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 0.9255 - val_direction_4h_accuracy: 0.5357 - val_direction_4h_binary_accuracy: 0.5357 - val_direction_4h_loss: 1.0141 - val_loss: 3.5096 - val_return_1h_loss: 2.7897e-04 - val_return_1h_mae: 0.0141 - val_return_1h_mse: 2.5910e-04 - val_return_24h_loss: 9.4154e-04 - val_return_24h_mae: 0.0262 - val_return_24h_mse: 8.1860e-04 - val_return_4h_loss: 7.5190e-05 - val_return_4h_mae: 0.0057 - val_return_4h_mse: 6.0868e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6065 - direction_1h_binary_accuracy: 0.6065 - direction_1h_loss: 0.6592 - direction_4h_accuracy: 0.7063 - direction_4h_binary_accuracy: 0.7063 - direction_4h_loss: 0.5559 - loss: 2.3249 - return_1h_loss: 8.4315e-04 - return_1h_mae: 0.0205 - return_1h_mse: 8.4314e-04 - return_24h_loss: 0.0011 - return_24h_mae: 0.0240 - return_24h_mse: 0.0011 - return_4h_loss: 6.1860e-04 - return_4h_mae: 0.0180 - return_4h_mse: 6.1863e-04\n",
            "Epoch 33: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6064 - direction_1h_binary_accuracy: 0.6064 - direction_1h_loss: 0.6592 - direction_4h_accuracy: 0.7067 - direction_4h_binary_accuracy: 0.7067 - direction_4h_loss: 0.5557 - loss: 2.3245 - return_1h_loss: 8.4143e-04 - return_1h_mae: 0.0205 - return_1h_mse: 8.4141e-04 - return_24h_loss: 0.0011 - return_24h_mae: 0.0240 - return_24h_mse: 0.0011 - return_4h_loss: 6.1844e-04 - return_4h_mae: 0.0180 - return_4h_mse: 6.1849e-04 - val_direction_1h_accuracy: 0.5226 - val_direction_1h_binary_accuracy: 0.5226 - val_direction_1h_loss: 0.9188 - val_direction_4h_accuracy: 0.5322 - val_direction_4h_binary_accuracy: 0.5322 - val_direction_4h_loss: 0.9937 - val_loss: 3.4527 - val_return_1h_loss: 2.4594e-04 - val_return_1h_mae: 0.0124 - val_return_1h_mse: 2.1767e-04 - val_return_24h_loss: 7.4092e-04 - val_return_24h_mae: 0.0227 - val_return_24h_mse: 6.4038e-04 - val_return_4h_loss: 6.4433e-05 - val_return_4h_mae: 0.0055 - val_return_4h_mse: 5.2965e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6173 - direction_1h_binary_accuracy: 0.6173 - direction_1h_loss: 0.6555 - direction_4h_accuracy: 0.7207 - direction_4h_binary_accuracy: 0.7207 - direction_4h_loss: 0.5424 - loss: 2.2969 - return_1h_loss: 7.1531e-04 - return_1h_mae: 0.0192 - return_1h_mse: 7.1541e-04 - return_24h_loss: 9.9990e-04 - return_24h_mae: 0.0222 - return_24h_mse: 9.9995e-04 - return_4h_loss: 5.5577e-04 - return_4h_mae: 0.0169 - return_4h_mse: 5.5570e-04\n",
            "Epoch 34: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6172 - direction_1h_binary_accuracy: 0.6172 - direction_1h_loss: 0.6555 - direction_4h_accuracy: 0.7208 - direction_4h_binary_accuracy: 0.7208 - direction_4h_loss: 0.5424 - loss: 2.2968 - return_1h_loss: 7.1403e-04 - return_1h_mae: 0.0192 - return_1h_mse: 7.1423e-04 - return_24h_loss: 9.9864e-04 - return_24h_mae: 0.0222 - return_24h_mse: 9.9874e-04 - return_4h_loss: 5.5559e-04 - return_4h_mae: 0.0169 - return_4h_mse: 5.5545e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 0.9376 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.0318 - val_loss: 3.5542 - val_return_1h_loss: 2.3409e-04 - val_return_1h_mae: 0.0122 - val_return_1h_mse: 2.1180e-04 - val_return_24h_loss: 8.7253e-04 - val_return_24h_mae: 0.0258 - val_return_24h_mse: 7.9911e-04 - val_return_4h_loss: 3.9378e-05 - val_return_4h_mae: 0.0044 - val_return_4h_mse: 3.4287e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6151 - direction_1h_binary_accuracy: 0.6151 - direction_1h_loss: 0.6546 - direction_4h_accuracy: 0.7317 - direction_4h_binary_accuracy: 0.7317 - direction_4h_loss: 0.5389 - loss: 2.2896 - return_1h_loss: 5.9466e-04 - return_1h_mae: 0.0179 - return_1h_mse: 5.9470e-04 - return_24h_loss: 8.2692e-04 - return_24h_mae: 0.0207 - return_24h_mse: 8.2692e-04 - return_4h_loss: 4.9208e-04 - return_4h_mae: 0.0160 - return_4h_mse: 4.9213e-04\n",
            "Epoch 35: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6150 - direction_1h_binary_accuracy: 0.6150 - direction_1h_loss: 0.6547 - direction_4h_accuracy: 0.7316 - direction_4h_binary_accuracy: 0.7316 - direction_4h_loss: 0.5389 - loss: 2.2896 - return_1h_loss: 5.9414e-04 - return_1h_mae: 0.0179 - return_1h_mse: 5.9423e-04 - return_24h_loss: 8.2623e-04 - return_24h_mae: 0.0207 - return_24h_mse: 8.2623e-04 - return_4h_loss: 4.9191e-04 - return_4h_mae: 0.0160 - return_4h_mse: 4.9201e-04 - val_direction_1h_accuracy: 0.5200 - val_direction_1h_binary_accuracy: 0.5200 - val_direction_1h_loss: 0.8618 - val_direction_4h_accuracy: 0.5322 - val_direction_4h_binary_accuracy: 0.5322 - val_direction_4h_loss: 0.9434 - val_loss: 3.2727 - val_return_1h_loss: 1.6889e-04 - val_return_1h_mae: 0.0106 - val_return_1h_mse: 1.6065e-04 - val_return_24h_loss: 7.3265e-04 - val_return_24h_mae: 0.0232 - val_return_24h_mse: 6.6534e-04 - val_return_4h_loss: 7.5061e-05 - val_return_4h_mae: 0.0059 - val_return_4h_mse: 6.3890e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6185 - direction_1h_binary_accuracy: 0.6185 - direction_1h_loss: 0.6543 - direction_4h_accuracy: 0.7228 - direction_4h_binary_accuracy: 0.7228 - direction_4h_loss: 0.5439 - loss: 2.2960 - return_1h_loss: 5.0830e-04 - return_1h_mae: 0.0164 - return_1h_mse: 5.0833e-04 - return_24h_loss: 7.7159e-04 - return_24h_mae: 0.0198 - return_24h_mse: 7.7169e-04 - return_4h_loss: 3.9994e-04 - return_4h_mae: 0.0146 - return_4h_mse: 3.9991e-04\n",
            "Epoch 36: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6185 - direction_1h_binary_accuracy: 0.6185 - direction_1h_loss: 0.6543 - direction_4h_accuracy: 0.7229 - direction_4h_binary_accuracy: 0.7229 - direction_4h_loss: 0.5436 - loss: 2.2957 - return_1h_loss: 5.0751e-04 - return_1h_mae: 0.0163 - return_1h_mse: 5.0756e-04 - return_24h_loss: 7.7104e-04 - return_24h_mae: 0.0198 - return_24h_mse: 7.7123e-04 - return_4h_loss: 3.9997e-04 - return_4h_mae: 0.0146 - return_4h_mse: 3.9991e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.0538 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.2755 - val_loss: 4.1320 - val_return_1h_loss: 2.3987e-04 - val_return_1h_mae: 0.0135 - val_return_1h_mse: 2.2808e-04 - val_return_24h_loss: 7.0612e-04 - val_return_24h_mae: 0.0242 - val_return_24h_mse: 6.6260e-04 - val_return_4h_loss: 5.3585e-05 - val_return_4h_mae: 0.0056 - val_return_4h_mse: 4.5304e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6134 - direction_1h_binary_accuracy: 0.6134 - direction_1h_loss: 0.6570 - direction_4h_accuracy: 0.7317 - direction_4h_binary_accuracy: 0.7317 - direction_4h_loss: 0.5452 - loss: 2.3033 - return_1h_loss: 4.5765e-04 - return_1h_mae: 0.0154 - return_1h_mse: 4.5768e-04 - return_24h_loss: 6.7249e-04 - return_24h_mae: 0.0184 - return_24h_mse: 6.7246e-04 - return_4h_loss: 3.5704e-04 - return_4h_mae: 0.0136 - return_4h_mse: 3.5703e-04\n",
            "Epoch 37: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6132 - direction_1h_binary_accuracy: 0.6132 - direction_1h_loss: 0.6570 - direction_4h_accuracy: 0.7315 - direction_4h_binary_accuracy: 0.7315 - direction_4h_loss: 0.5451 - loss: 2.3030 - return_1h_loss: 4.5704e-04 - return_1h_mae: 0.0154 - return_1h_mse: 4.5710e-04 - return_24h_loss: 6.7226e-04 - return_24h_mae: 0.0184 - return_24h_mse: 6.7219e-04 - return_4h_loss: 3.5672e-04 - return_4h_mae: 0.0136 - return_4h_mse: 3.5669e-04 - val_direction_1h_accuracy: 0.5322 - val_direction_1h_binary_accuracy: 0.5322 - val_direction_1h_loss: 0.7845 - val_direction_4h_accuracy: 0.4687 - val_direction_4h_binary_accuracy: 0.4687 - val_direction_4h_loss: 0.8678 - val_loss: 3.0045 - val_return_1h_loss: 7.9796e-05 - val_return_1h_mae: 0.0072 - val_return_1h_mse: 7.1036e-05 - val_return_24h_loss: 0.0012 - val_return_24h_mae: 0.0304 - val_return_24h_mse: 0.0011 - val_return_4h_loss: 4.5796e-05 - val_return_4h_mae: 0.0051 - val_return_4h_mse: 4.2968e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6168 - direction_1h_binary_accuracy: 0.6168 - direction_1h_loss: 0.6540 - direction_4h_accuracy: 0.7308 - direction_4h_binary_accuracy: 0.7308 - direction_4h_loss: 0.5374 - loss: 2.2852 - return_1h_loss: 4.0615e-04 - return_1h_mae: 0.0144 - return_1h_mse: 4.0617e-04 - return_24h_loss: 6.1343e-04 - return_24h_mae: 0.0175 - return_24h_mse: 6.1346e-04 - return_4h_loss: 3.1118e-04 - return_4h_mae: 0.0127 - return_4h_mse: 3.1121e-04\n",
            "Epoch 38: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6169 - direction_1h_binary_accuracy: 0.6169 - direction_1h_loss: 0.6539 - direction_4h_accuracy: 0.7309 - direction_4h_binary_accuracy: 0.7309 - direction_4h_loss: 0.5372 - loss: 2.2847 - return_1h_loss: 4.0528e-04 - return_1h_mae: 0.0144 - return_1h_mse: 4.0532e-04 - return_24h_loss: 6.1290e-04 - return_24h_mae: 0.0175 - return_24h_mse: 6.1296e-04 - return_4h_loss: 3.1080e-04 - return_4h_mae: 0.0126 - return_4h_mse: 3.1086e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 0.9927 - val_direction_4h_accuracy: 0.5313 - val_direction_4h_binary_accuracy: 0.5313 - val_direction_4h_loss: 1.1698 - val_loss: 3.8428 - val_return_1h_loss: 3.4014e-05 - val_return_1h_mae: 0.0045 - val_return_1h_mse: 3.0170e-05 - val_return_24h_loss: 0.0012 - val_return_24h_mae: 0.0330 - val_return_24h_mse: 0.0012 - val_return_4h_loss: 3.9735e-05 - val_return_4h_mae: 0.0046 - val_return_4h_mse: 3.3837e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6226 - direction_1h_binary_accuracy: 0.6226 - direction_1h_loss: 0.6494 - direction_4h_accuracy: 0.7250 - direction_4h_binary_accuracy: 0.7250 - direction_4h_loss: 0.5417 - loss: 2.2821 - return_1h_loss: 3.3775e-04 - return_1h_mae: 0.0133 - return_1h_mse: 3.3777e-04 - return_24h_loss: 5.0269e-04 - return_24h_mae: 0.0161 - return_24h_mse: 5.0270e-04 - return_4h_loss: 2.6779e-04 - return_4h_mae: 0.0116 - return_4h_mse: 2.6782e-04\n",
            "Epoch 39: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6225 - direction_1h_binary_accuracy: 0.6225 - direction_1h_loss: 0.6493 - direction_4h_accuracy: 0.7250 - direction_4h_binary_accuracy: 0.7250 - direction_4h_loss: 0.5417 - loss: 2.2821 - return_1h_loss: 3.3726e-04 - return_1h_mae: 0.0133 - return_1h_mse: 3.3728e-04 - return_24h_loss: 5.0253e-04 - return_24h_mae: 0.0161 - return_24h_mse: 5.0254e-04 - return_4h_loss: 2.6737e-04 - return_4h_mae: 0.0116 - return_4h_mse: 2.6742e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.2047 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.5799 - val_loss: 4.8520 - val_return_1h_loss: 9.0569e-05 - val_return_1h_mae: 0.0073 - val_return_1h_mse: 7.7382e-05 - val_return_24h_loss: 9.1319e-04 - val_return_24h_mae: 0.0282 - val_return_24h_mse: 8.6635e-04 - val_return_4h_loss: 4.4676e-05 - val_return_4h_mae: 0.0052 - val_return_4h_mse: 3.9863e-05 - learning_rate: 2.5000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6046 - direction_1h_binary_accuracy: 0.6046 - direction_1h_loss: 0.6557 - direction_4h_accuracy: 0.7150 - direction_4h_binary_accuracy: 0.7150 - direction_4h_loss: 0.5477 - loss: 2.3035 - return_1h_loss: 2.7330e-04 - return_1h_mae: 0.0120 - return_1h_mse: 2.7328e-04 - return_24h_loss: 4.7737e-04 - return_24h_mae: 0.0151 - return_24h_mse: 4.7746e-04 - return_4h_loss: 2.3274e-04 - return_4h_mae: 0.0109 - return_4h_mse: 2.3278e-04\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 40: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6045 - direction_1h_binary_accuracy: 0.6045 - direction_1h_loss: 0.6557 - direction_4h_accuracy: 0.7152 - direction_4h_binary_accuracy: 0.7152 - direction_4h_loss: 0.5475 - loss: 2.3034 - return_1h_loss: 2.7344e-04 - return_1h_mae: 0.0120 - return_1h_mse: 2.7339e-04 - return_24h_loss: 4.7647e-04 - return_24h_mae: 0.0151 - return_24h_mse: 4.7665e-04 - return_4h_loss: 2.3218e-04 - return_4h_mae: 0.0109 - return_4h_mse: 2.3225e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.0374 - val_direction_4h_accuracy: 0.5348 - val_direction_4h_binary_accuracy: 0.5348 - val_direction_4h_loss: 1.2697 - val_loss: 4.0557 - val_return_1h_loss: 6.7579e-05 - val_return_1h_mae: 0.0062 - val_return_1h_mse: 5.7004e-05 - val_return_24h_loss: 7.4917e-04 - val_return_24h_mae: 0.0254 - val_return_24h_mse: 7.0963e-04 - val_return_4h_loss: 1.3848e-04 - val_return_4h_mae: 0.0091 - val_return_4h_mse: 1.1659e-04 - learning_rate: 2.5000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6260 - direction_1h_binary_accuracy: 0.6260 - direction_1h_loss: 0.6482 - direction_4h_accuracy: 0.7322 - direction_4h_binary_accuracy: 0.7322 - direction_4h_loss: 0.5318 - loss: 2.2645 - return_1h_loss: 2.6527e-04 - return_1h_mae: 0.0116 - return_1h_mse: 2.6527e-04 - return_24h_loss: 3.8526e-04 - return_24h_mae: 0.0141 - return_24h_mse: 3.8528e-04 - return_4h_loss: 2.0006e-04 - return_4h_mae: 0.0100 - return_4h_mse: 2.0005e-04\n",
            "Epoch 41: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6261 - direction_1h_binary_accuracy: 0.6261 - direction_1h_loss: 0.6481 - direction_4h_accuracy: 0.7325 - direction_4h_binary_accuracy: 0.7325 - direction_4h_loss: 0.5314 - loss: 2.2638 - return_1h_loss: 2.6496e-04 - return_1h_mae: 0.0115 - return_1h_mse: 2.6495e-04 - return_24h_loss: 3.8526e-04 - return_24h_mae: 0.0141 - return_24h_mse: 3.8531e-04 - return_4h_loss: 1.9967e-04 - return_4h_mae: 0.0100 - return_4h_mse: 1.9966e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.0345 - val_direction_4h_accuracy: 0.5374 - val_direction_4h_binary_accuracy: 0.5374 - val_direction_4h_loss: 1.2825 - val_loss: 4.0781 - val_return_1h_loss: 1.2842e-04 - val_return_1h_mae: 0.0095 - val_return_1h_mse: 1.1573e-04 - val_return_24h_loss: 9.9096e-04 - val_return_24h_mae: 0.0290 - val_return_24h_mse: 9.2431e-04 - val_return_4h_loss: 7.2647e-05 - val_return_4h_mae: 0.0064 - val_return_4h_mse: 5.9576e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6283 - direction_1h_binary_accuracy: 0.6283 - direction_1h_loss: 0.6428 - direction_4h_accuracy: 0.7567 - direction_4h_binary_accuracy: 0.7567 - direction_4h_loss: 0.5019 - loss: 2.2087 - return_1h_loss: 2.2506e-04 - return_1h_mae: 0.0108 - return_1h_mse: 2.2503e-04 - return_24h_loss: 3.5584e-04 - return_24h_mae: 0.0136 - return_24h_mse: 3.5582e-04 - return_4h_loss: 1.7274e-04 - return_4h_mae: 0.0096 - return_4h_mse: 1.7275e-04\n",
            "Epoch 42: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6284 - direction_1h_binary_accuracy: 0.6284 - direction_1h_loss: 0.6427 - direction_4h_accuracy: 0.7567 - direction_4h_binary_accuracy: 0.7567 - direction_4h_loss: 0.5018 - loss: 2.2084 - return_1h_loss: 2.2511e-04 - return_1h_mae: 0.0108 - return_1h_mse: 2.2506e-04 - return_24h_loss: 3.5558e-04 - return_24h_mae: 0.0136 - return_24h_mse: 3.5553e-04 - return_4h_loss: 1.7283e-04 - return_4h_mae: 0.0096 - return_4h_mse: 1.7284e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.1958 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.6153 - val_loss: 4.8795 - val_return_1h_loss: 1.1554e-04 - val_return_1h_mae: 0.0091 - val_return_1h_mse: 1.0361e-04 - val_return_24h_loss: 9.5003e-04 - val_return_24h_mae: 0.0284 - val_return_24h_mse: 8.8434e-04 - val_return_4h_loss: 1.2521e-04 - val_return_4h_mae: 0.0089 - val_return_4h_mse: 1.0788e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6336 - direction_1h_binary_accuracy: 0.6336 - direction_1h_loss: 0.6456 - direction_4h_accuracy: 0.7630 - direction_4h_binary_accuracy: 0.7630 - direction_4h_loss: 0.4953 - loss: 2.2044 - return_1h_loss: 1.9878e-04 - return_1h_mae: 0.0104 - return_1h_mse: 1.9878e-04 - return_24h_loss: 3.5281e-04 - return_24h_mae: 0.0133 - return_24h_mse: 3.5286e-04 - return_4h_loss: 1.5980e-04 - return_4h_mae: 0.0092 - return_4h_mse: 1.5978e-04\n",
            "Epoch 43: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6337 - direction_1h_binary_accuracy: 0.6337 - direction_1h_loss: 0.6455 - direction_4h_accuracy: 0.7631 - direction_4h_binary_accuracy: 0.7631 - direction_4h_loss: 0.4950 - loss: 2.2037 - return_1h_loss: 1.9880e-04 - return_1h_mae: 0.0104 - return_1h_mse: 1.9881e-04 - return_24h_loss: 3.5243e-04 - return_24h_mae: 0.0133 - return_24h_mse: 3.5252e-04 - return_4h_loss: 1.5980e-04 - return_4h_mae: 0.0092 - return_4h_mse: 1.5976e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.0627 - val_direction_4h_accuracy: 0.5357 - val_direction_4h_binary_accuracy: 0.5357 - val_direction_4h_loss: 1.3544 - val_loss: 4.2358 - val_return_1h_loss: 8.4920e-05 - val_return_1h_mae: 0.0075 - val_return_1h_mse: 7.6046e-05 - val_return_24h_loss: 7.5541e-04 - val_return_24h_mae: 0.0254 - val_return_24h_mse: 7.0720e-04 - val_return_4h_loss: 9.6717e-05 - val_return_4h_mae: 0.0076 - val_return_4h_mse: 8.0515e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6349 - direction_1h_binary_accuracy: 0.6349 - direction_1h_loss: 0.6389 - direction_4h_accuracy: 0.7629 - direction_4h_binary_accuracy: 0.7629 - direction_4h_loss: 0.4936 - loss: 2.1884 - return_1h_loss: 1.9151e-04 - return_1h_mae: 0.0100 - return_1h_mse: 1.9153e-04 - return_24h_loss: 3.0822e-04 - return_24h_mae: 0.0127 - return_24h_mse: 3.0823e-04 - return_4h_loss: 1.5738e-04 - return_4h_mae: 0.0089 - return_4h_mse: 1.5738e-04\n",
            "Epoch 44: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6350 - direction_1h_binary_accuracy: 0.6350 - direction_1h_loss: 0.6388 - direction_4h_accuracy: 0.7631 - direction_4h_binary_accuracy: 0.7631 - direction_4h_loss: 0.4932 - loss: 2.1878 - return_1h_loss: 1.9148e-04 - return_1h_mae: 0.0100 - return_1h_mse: 1.9152e-04 - return_24h_loss: 3.0833e-04 - return_24h_mae: 0.0127 - return_24h_mse: 3.0835e-04 - return_4h_loss: 1.5728e-04 - return_4h_mae: 0.0089 - return_4h_mse: 1.5728e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.1871 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.6030 - val_loss: 4.8556 - val_return_1h_loss: 8.1058e-05 - val_return_1h_mae: 0.0077 - val_return_1h_mse: 7.2995e-05 - val_return_24h_loss: 5.9509e-04 - val_return_24h_mae: 0.0225 - val_return_24h_mse: 5.6095e-04 - val_return_4h_loss: 1.1667e-04 - val_return_4h_mae: 0.0088 - val_return_4h_mse: 1.0030e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6311 - direction_1h_binary_accuracy: 0.6311 - direction_1h_loss: 0.6387 - direction_4h_accuracy: 0.7700 - direction_4h_binary_accuracy: 0.7700 - direction_4h_loss: 0.4806 - loss: 2.1684 - return_1h_loss: 1.7605e-04 - return_1h_mae: 0.0097 - return_1h_mse: 1.7606e-04 - return_24h_loss: 2.6854e-04 - return_24h_mae: 0.0119 - return_24h_mse: 2.6854e-04 - return_4h_loss: 1.3975e-04 - return_4h_mae: 0.0085 - return_4h_mse: 1.3973e-04\n",
            "Epoch 45: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6313 - direction_1h_binary_accuracy: 0.6313 - direction_1h_loss: 0.6387 - direction_4h_accuracy: 0.7700 - direction_4h_binary_accuracy: 0.7700 - direction_4h_loss: 0.4805 - loss: 2.1681 - return_1h_loss: 1.7591e-04 - return_1h_mae: 0.0097 - return_1h_mse: 1.7592e-04 - return_24h_loss: 2.6865e-04 - return_24h_mae: 0.0119 - return_24h_mse: 2.6864e-04 - return_4h_loss: 1.3968e-04 - return_4h_mae: 0.0085 - return_4h_mse: 1.3964e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.2444 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.7397 - val_loss: 5.1587 - val_return_1h_loss: 1.0273e-04 - val_return_1h_mae: 0.0087 - val_return_1h_mse: 9.3493e-05 - val_return_24h_loss: 3.7539e-04 - val_return_24h_mae: 0.0178 - val_return_24h_mse: 3.5876e-04 - val_return_4h_loss: 1.3843e-04 - val_return_4h_mae: 0.0098 - val_return_4h_mse: 1.1981e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6446 - direction_1h_binary_accuracy: 0.6446 - direction_1h_loss: 0.6372 - direction_4h_accuracy: 0.7772 - direction_4h_binary_accuracy: 0.7772 - direction_4h_loss: 0.4743 - loss: 2.1557 - return_1h_loss: 1.5868e-04 - return_1h_mae: 0.0091 - return_1h_mse: 1.5871e-04 - return_24h_loss: 2.5387e-04 - return_24h_mae: 0.0114 - return_24h_mse: 2.5382e-04 - return_4h_loss: 1.2406e-04 - return_4h_mae: 0.0080 - return_4h_mse: 1.2404e-04\n",
            "Epoch 46: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6446 - direction_1h_binary_accuracy: 0.6446 - direction_1h_loss: 0.6371 - direction_4h_accuracy: 0.7772 - direction_4h_binary_accuracy: 0.7772 - direction_4h_loss: 0.4740 - loss: 2.1553 - return_1h_loss: 1.5853e-04 - return_1h_mae: 0.0091 - return_1h_mse: 1.5858e-04 - return_24h_loss: 2.5417e-04 - return_24h_mae: 0.0114 - return_24h_mse: 2.5408e-04 - return_4h_loss: 1.2411e-04 - return_4h_mae: 0.0080 - return_4h_mse: 1.2408e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.2140 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.6876 - val_loss: 5.0262 - val_return_1h_loss: 6.2306e-05 - val_return_1h_mae: 0.0064 - val_return_1h_mse: 5.5876e-05 - val_return_24h_loss: 3.7477e-04 - val_return_24h_mae: 0.0178 - val_return_24h_mse: 3.5731e-04 - val_return_4h_loss: 1.2025e-04 - val_return_4h_mae: 0.0093 - val_return_4h_mse: 1.0614e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6428 - direction_1h_binary_accuracy: 0.6428 - direction_1h_loss: 0.6379 - direction_4h_accuracy: 0.7696 - direction_4h_binary_accuracy: 0.7696 - direction_4h_loss: 0.4749 - loss: 2.1579 - return_1h_loss: 1.3949e-04 - return_1h_mae: 0.0087 - return_1h_mse: 1.3949e-04 - return_24h_loss: 2.4881e-04 - return_24h_mae: 0.0114 - return_24h_mse: 2.4876e-04 - return_4h_loss: 1.1042e-04 - return_4h_mae: 0.0076 - return_4h_mse: 1.1042e-04\n",
            "Epoch 47: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6428 - direction_1h_binary_accuracy: 0.6428 - direction_1h_loss: 0.6378 - direction_4h_accuracy: 0.7697 - direction_4h_binary_accuracy: 0.7697 - direction_4h_loss: 0.4748 - loss: 2.1575 - return_1h_loss: 1.3952e-04 - return_1h_mae: 0.0087 - return_1h_mse: 1.3952e-04 - return_24h_loss: 2.4866e-04 - return_24h_mae: 0.0114 - return_24h_mse: 2.4858e-04 - return_4h_loss: 1.1052e-04 - return_4h_mae: 0.0076 - return_4h_mse: 1.1054e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.1996 - val_direction_4h_accuracy: 0.5374 - val_direction_4h_binary_accuracy: 0.5374 - val_direction_4h_loss: 1.6513 - val_loss: 4.9354 - val_return_1h_loss: 4.8631e-05 - val_return_1h_mae: 0.0059 - val_return_1h_mse: 4.4989e-05 - val_return_24h_loss: 3.5821e-04 - val_return_24h_mae: 0.0174 - val_return_24h_mse: 3.4491e-04 - val_return_4h_loss: 1.2906e-04 - val_return_4h_mae: 0.0094 - val_return_4h_mse: 1.1131e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6419 - direction_1h_binary_accuracy: 0.6419 - direction_1h_loss: 0.6387 - direction_4h_accuracy: 0.7698 - direction_4h_binary_accuracy: 0.7698 - direction_4h_loss: 0.4779 - loss: 2.1639 - return_1h_loss: 1.3821e-04 - return_1h_mae: 0.0085 - return_1h_mse: 1.3823e-04 - return_24h_loss: 2.2236e-04 - return_24h_mae: 0.0106 - return_24h_mse: 2.2241e-04 - return_4h_loss: 1.1253e-04 - return_4h_mae: 0.0077 - return_4h_mse: 1.1253e-04\n",
            "Epoch 48: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6419 - direction_1h_binary_accuracy: 0.6419 - direction_1h_loss: 0.6386 - direction_4h_accuracy: 0.7699 - direction_4h_binary_accuracy: 0.7699 - direction_4h_loss: 0.4776 - loss: 2.1634 - return_1h_loss: 1.3810e-04 - return_1h_mae: 0.0085 - return_1h_mse: 1.3813e-04 - return_24h_loss: 2.2251e-04 - return_24h_mae: 0.0106 - return_24h_mse: 2.2259e-04 - return_4h_loss: 1.1233e-04 - return_4h_mae: 0.0077 - return_4h_mse: 1.1235e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.0859 - val_direction_4h_accuracy: 0.5322 - val_direction_4h_binary_accuracy: 0.5322 - val_direction_4h_loss: 1.4443 - val_loss: 4.4290 - val_return_1h_loss: 3.2434e-05 - val_return_1h_mae: 0.0046 - val_return_1h_mse: 2.9327e-05 - val_return_24h_loss: 3.1121e-04 - val_return_24h_mae: 0.0160 - val_return_24h_mse: 2.9811e-04 - val_return_4h_loss: 6.4324e-05 - val_return_4h_mae: 0.0065 - val_return_4h_mse: 5.5911e-05 - learning_rate: 1.2500e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6404 - direction_1h_binary_accuracy: 0.6404 - direction_1h_loss: 0.6381 - direction_4h_accuracy: 0.7780 - direction_4h_binary_accuracy: 0.7780 - direction_4h_loss: 0.4743 - loss: 2.1572 - return_1h_loss: 1.2110e-04 - return_1h_mae: 0.0080 - return_1h_mse: 1.2108e-04 - return_24h_loss: 2.0719e-04 - return_24h_mae: 0.0102 - return_24h_mse: 2.0721e-04 - return_4h_loss: 1.0059e-04 - return_4h_mae: 0.0071 - return_4h_mse: 1.0060e-04\n",
            "Epoch 49: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6404 - direction_1h_binary_accuracy: 0.6404 - direction_1h_loss: 0.6380 - direction_4h_accuracy: 0.7777 - direction_4h_binary_accuracy: 0.7777 - direction_4h_loss: 0.4743 - loss: 2.1572 - return_1h_loss: 1.2098e-04 - return_1h_mae: 0.0080 - return_1h_mse: 1.2095e-04 - return_24h_loss: 2.0714e-04 - return_24h_mae: 0.0102 - return_24h_mse: 2.0718e-04 - return_4h_loss: 1.0041e-04 - return_4h_mae: 0.0071 - return_4h_mse: 1.0043e-04 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.2638 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 1.8971 - val_loss: 5.4224 - val_return_1h_loss: 2.6660e-05 - val_return_1h_mae: 0.0041 - val_return_1h_mse: 2.4911e-05 - val_return_24h_loss: 2.8843e-04 - val_return_24h_mae: 0.0157 - val_return_24h_mse: 2.8124e-04 - val_return_4h_loss: 1.5852e-04 - val_return_4h_mae: 0.0108 - val_return_4h_mse: 1.4035e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - direction_1h_accuracy: 0.6361 - direction_1h_binary_accuracy: 0.6361 - direction_1h_loss: 0.6364 - direction_4h_accuracy: 0.7643 - direction_4h_binary_accuracy: 0.7643 - direction_4h_loss: 0.4766 - loss: 2.1572 - return_1h_loss: 1.0374e-04 - return_1h_mae: 0.0075 - return_1h_mse: 1.0375e-04 - return_24h_loss: 1.8234e-04 - return_24h_mae: 0.0098 - return_24h_mse: 1.8234e-04 - return_4h_loss: 8.3995e-05 - return_4h_mae: 0.0066 - return_4h_mse: 8.3994e-05\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 50: val_loss did not improve from 2.62667\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - direction_1h_accuracy: 0.6362 - direction_1h_binary_accuracy: 0.6362 - direction_1h_loss: 0.6364 - direction_4h_accuracy: 0.7645 - direction_4h_binary_accuracy: 0.7645 - direction_4h_loss: 0.4764 - loss: 2.1568 - return_1h_loss: 1.0381e-04 - return_1h_mae: 0.0075 - return_1h_mse: 1.0382e-04 - return_24h_loss: 1.8244e-04 - return_24h_mae: 0.0098 - return_24h_mse: 1.8244e-04 - return_4h_loss: 8.4021e-05 - return_4h_mae: 0.0066 - return_4h_mse: 8.4017e-05 - val_direction_1h_accuracy: 0.5243 - val_direction_1h_binary_accuracy: 0.5243 - val_direction_1h_loss: 1.4097 - val_direction_4h_accuracy: 0.5383 - val_direction_4h_binary_accuracy: 0.5383 - val_direction_4h_loss: 2.1977 - val_loss: 6.1711 - val_return_1h_loss: 3.4626e-05 - val_return_1h_mae: 0.0049 - val_return_1h_mse: 3.3465e-05 - val_return_24h_loss: 3.4080e-04 - val_return_24h_mae: 0.0172 - val_return_24h_mse: 3.3147e-04 - val_return_4h_loss: 1.5112e-04 - val_return_4h_mae: 0.0107 - val_return_4h_mse: 1.3551e-04 - learning_rate: 1.2500e-04\n",
            "Epoch 50: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step\n",
            "=== EVALUACIÓN DE REGRESIÓN ===\n",
            "Horizonte 1H:\n",
            "  MSE: 0.000873\n",
            "  MAE: 0.023398\n",
            "  R²: -1187.6028\n",
            "Horizonte 4H:\n",
            "  MSE: 0.000921\n",
            "  MAE: 0.025627\n",
            "  R²: -334.9755\n",
            "Horizonte 24H:\n",
            "  MSE: 0.000696\n",
            "  MAE: 0.020114\n",
            "  R²: -44.7579\n",
            "\n",
            "=== EVALUACIÓN DE CLASIFICACIÓN ===\n",
            "Dirección 1H:\n",
            "  Accuracy: 0.4941\n",
            "  Precision: 0.4927\n",
            "  Recall: 0.7061\n",
            "  F1-Score: 0.5804\n",
            "  Matriz de confusión:\n",
            "[[332 829]\n",
            " [335 805]]\n",
            "Dirección 4H:\n",
            "  Accuracy: 0.5007\n",
            "  Precision: 0.4964\n",
            "  Recall: 0.5970\n",
            "  F1-Score: 0.5420\n",
            "  Matriz de confusión:\n",
            "[[472 690]\n",
            " [459 680]]\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step\n",
            "Retorno total: -4.31%\n",
            "Número de trades: 1\n",
            "Capital final: $9568.70\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"8caf1c20-8de1-4cc2-bc5f-c9f2426c5a3b\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8caf1c20-8de1-4cc2-bc5f-c9f2426c5a3b\")) {                    Plotly.newPlot(                        \"8caf1c20-8de1-4cc2-bc5f-c9f2426c5a3b\",                        [{\"name\":\"Train Loss\",\"y\":[7.5256853103637695,5.116120338439941,4.259809970855713,3.799520969390869,3.4815480709075928,3.261282205581665,3.0923268795013428,2.967402935028076,2.8742589950561523,2.793947219848633,2.7453949451446533,2.6948108673095703,2.670793294906616,2.6537487506866455,2.6172549724578857,2.60868239402771,2.5902249813079834,2.5516090393066406,2.5299715995788574,2.5192110538482666,2.4945695400238037,2.4895434379577637,2.4838385581970215,2.466026782989502,2.4472196102142334,2.4297101497650146,2.410606861114502,2.419781446456909,2.423327684402466,2.3982291221618652,2.3730781078338623,2.3307416439056396,2.3118271827697754,2.2960822582244873,2.289194107055664,2.283818244934082,2.2955992221832275,2.2684881687164307,2.280623435974121,2.2994725704193115,2.2438411712646484,2.19966197013855,2.1818065643310547,2.167524576187134,2.158155918121338,2.1424756050109863,2.1445529460906982,2.146807909011841,2.1557154655456543,2.14505934715271],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Val Loss\",\"y\":[2.7606027126312256,3.0996134281158447,2.847133159637451,2.807321786880493,2.7644169330596924,2.824256181716919,2.8521649837493896,2.851290225982666,2.914811849594116,2.8294217586517334,2.843568801879883,2.8705902099609375,2.8637311458587646,2.850450277328491,2.810883045196533,2.712198495864868,2.678204298019409,2.6912059783935547,2.637619972229004,2.626668691635132,2.6346938610076904,2.6586103439331055,2.7217252254486084,2.7788376808166504,2.7156269550323486,2.988725185394287,2.9945871829986572,3.0052788257598877,3.8820126056671143,2.804680109024048,2.9273648262023926,3.5096395015716553,3.4526610374450684,3.55424165725708,3.272728443145752,4.131967544555664,3.0045011043548584,3.8428032398223877,4.851970672607422,4.0556769371032715,4.078107833862305,4.879512786865234,4.235760688781738,4.855575084686279,5.158658504486084,5.026237487792969,4.935362339019775,4.4290361404418945,5.422366142272949,6.171076774597168],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Train Acc 1H\",\"y\":[0.5089440941810608,0.5,0.5079503059387207,0.5045962929725647,0.5114285945892334,0.5125465989112854,0.5094410181045532,0.5198757648468018,0.5199999809265137,0.531552791595459,0.5289440751075745,0.5380124449729919,0.5500621199607849,0.5378881692886353,0.5368943810462952,0.5508074760437012,0.5545341372489929,0.5609937906265259,0.5683229565620422,0.5668323040008545,0.5706832408905029,0.5662111639976501,0.5719254612922668,0.5788819789886475,0.5867080688476562,0.58596271276474,0.5894410014152527,0.5862112045288086,0.5843478441238403,0.5899378657341003,0.5961490869522095,0.6040993928909302,0.6053416132926941,0.6124223470687866,0.6115527749061584,0.6206211447715759,0.6088199019432068,0.6191304326057434,0.6200000047683716,0.6031056046485901,0.6295652389526367,0.6309316754341125,0.6360248327255249,0.638136625289917,0.6355279684066772,0.6442236304283142,0.6439751386642456,0.6408695578575134,0.6387577652931213,0.6378881931304932],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"Val Acc 1H\",\"y\":[0.47565218806266785,0.4991304278373718,0.5043478012084961,0.5130434632301331,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.47565218806266785,0.4773913025856018,0.47913044691085815,0.4843478202819824,0.5060869455337524,0.5078260898590088,0.5165217518806458,0.5139130353927612,0.5208695530891418,0.5278260707855225,0.5295652151107788,0.5226086974143982,0.5208695530891418,0.5208695530891418,0.5243478417396545,0.5104348063468933,0.5226086974143982,0.5243478417396545,0.5226086974143982,0.5243478417396545,0.5199999809265137,0.5243478417396545,0.5321739315986633,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545,0.5243478417396545],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"Train MAE 1H\",\"y\":[0.9984959959983826,0.6901731491088867,0.5654950737953186,0.47302672266960144,0.39704737067222595,0.34895578026771545,0.2977123260498047,0.2629028260707855,0.22655007243156433,0.19917188584804535,0.16864076256752014,0.1521195024251938,0.13958890736103058,0.1303795427083969,0.12002260237932205,0.11211461573839188,0.10212159156799316,0.09246048331260681,0.08418606966733932,0.07929756492376328,0.07069933414459229,0.06506674736738205,0.05756518244743347,0.05057556554675102,0.04612120985984802,0.04049172252416611,0.036992836743593216,0.032752737402915955,0.028276333585381508,0.02538742683827877,0.023243140429258347,0.02173864282667637,0.020284194499254227,0.01880726031959057,0.017634263262152672,0.016024326905608177,0.015159014612436295,0.014144094660878181,0.013092800974845886,0.012101511470973492,0.011459866538643837,0.010891835205256939,0.010397550649940968,0.010036644525825977,0.009614209644496441,0.009032271802425385,0.008647630922496319,0.008438827469944954,0.007883146405220032,0.007534923031926155],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"Val MAE 1H\",\"y\":[0.04780475050210953,0.3029160797595978,0.29715192317962646,0.23922066390514374,0.10627267509698868,0.11222788691520691,0.17090608179569244,0.159977525472641,0.14740149676799774,0.10309697687625885,0.04769982770085335,0.0785934329032898,0.07411301136016846,0.0506591871380806,0.05159429833292961,0.02858966402709484,0.021737975999712944,0.021203473210334778,0.01954730600118637,0.018393386155366898,0.018771862611174583,0.017806636169552803,0.031220965087413788,0.01689068414270878,0.018159769475460052,0.022211719304323196,0.022795671597123146,0.013260017149150372,0.021207408979535103,0.008586784824728966,0.010812293738126755,0.014070341363549232,0.01237854640930891,0.012238570488989353,0.010572565719485283,0.01347512286156416,0.007201720494776964,0.004500844981521368,0.0073177870362997055,0.006219752132892609,0.009540959261357784,0.009111989289522171,0.007537727244198322,0.007667301222681999,0.008687297813594341,0.0064168828539550304,0.0058621736243367195,0.004602943081408739,0.0041357907466590405,0.004865037743002176],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Loss\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Direction Accuracy\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Returns MAE\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Learning Rate\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"M\\u00e9tricas de Entrenamiento\"},\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8caf1c20-8de1-4cc2-bc5f-c9f2426c5a3b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c55cbe40-d962-40e0-870e-5d55eb1c09c8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c55cbe40-d962-40e0-870e-5d55eb1c09c8\")) {                    Plotly.newPlot(                        \"c55cbe40-d962-40e0-870e-5d55eb1c09c8\",                        [{\"line\":{\"color\":\"blue\"},\"name\":\"Portfolio Value\",\"y\":[10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,10000.0,9998.04,10000.32436564419,9999.753274233142,10006.820530444853,9997.040590030667,10004.036459815998,10004.893096932568,10007.106076150378,10011.317875306853,10005.82112047552,10026.023479141324,10030.44943757694,10031.805779678178,10031.663006825416,10016.671857285422,10007.320235429519,10001.038229908,9990.615811656384,9995.113156518382,9995.470088650287,10004.10784624238,10004.750324079807,10006.392211886568,10010.818170322185,10010.175692484756,10008.391031825235,10010.3898517639,10012.317285276185,10004.96448335895,10010.818170322185,10010.46123819028,10009.176282515426,10003.750914110475,9997.825840720856,9981.90666763791,9976.195753527436,9970.913157975248,9980.33616625753,9951.06773144135,9911.80519693184,9896.528501686322,9901.73971081213,9921.299591640503,9928.366847852216,9930.008735658977,9932.293101303167,9931.722009892119,9930.865372775548,9942.287200996496,9945.570976610017,9941.573336732687,9940.145608205068,9941.287791027164,9931.07953205469,9926.153868634407,9927.367437882884,9934.506080520974,9942.287200996496,9945.71374946278,9952.352687116207,9945.642363036399,9949.711389340111,9947.355637269542,9917.15917891041,9948.711979370779,9939.57451679402,9944.143248082399,9942.429973849257,9939.860062499545,9935.791036195831,9939.50313036764,9945.071271625353,9943.143838113067,9944.571566640687,9953.42348351192,9951.710209278779,9940.859472468877,9944.428793787923,9947.712569401447,9958.991624769633,9960.776285429156,9960.776285429156,9948.140887959733,9952.138527837064,9947.355637269542,9940.716699616116,9940.431153910593,9931.579237039357,9941.644723159068,9936.933219017927,9938.218174692784,9940.074221778686,9941.145018174402,9944.571566640687,9942.287200996496,9938.575106824688,9936.576286886022,9944.21463450878,9942.715519554782,9940.074221778686,9930.36566779088,9926.582187192693,9926.225255060786,9918.586907438028,9922.941479447265,9915.51729110365,9909.592217714031,9892.673634661753,9913.232925459459,9908.164489186413,9917.516111042314,9918.872453143553,9926.225255060786,9932.150328450405,9932.221714876787,9902.953280060607,9910.23469555146,9914.660653987077,9913.447084738602,9907.022306364319,9908.09310276003,9919.300771701837,9923.29841157917,9926.867732898216,9924.583367254027,9928.509620704977,9930.080122085357,9928.866552836882,9926.867732898216,9925.939709355265,9935.57687691669,9915.017586118982,9902.953280060607,9890.103723312039,9887.319652683182,9890.817587575848,9872.685435275092,9866.974521164619,9886.819947698516,9891.103133281373,9900.668914416416,9901.953870091273,9898.884253756893,9901.02584654832,9895.314932437846,9901.454165106607,9895.529091716988,9896.599888112703,9896.742660965465,9888.03351694699,9884.392809201565,9896.100183128037,9897.313752376513,9908.378648465556,9896.314342407179,9907.307852069842,9904.238235735462,9894.244136042133,9890.2464961648,9912.304901916506,9896.45711525994,9897.88484378756,9894.458295321276,9895.100773158703,9898.67009447775,9897.88484378756,9902.881893634225,9896.528501686322,9896.100183128037,9898.812867330513,9905.094872852034,9913.375698312222,9911.376878373556,9911.376878373556,9909.44944486127,9910.091922698697,9912.875993327554,9914.303721855173,9915.160358971743,9910.663014109747,9913.018766180316,9905.880123542223,9892.673634661753,9878.110803680043,9872.828208127854,9874.398709508236,9883.25062637947,9880.680715029757,9886.106083434706,9888.247676226134,9889.104313342707,9891.888383971562,9888.104903373373,9895.529091716988,9892.173929677085,9874.255936655472,9876.968620857948,9873.684845244426,9881.465965719946,9875.183960198425,9879.252986502139,9859.33617354186,9864.475996241286,9860.406969937572,9865.832338342523,9856.123784354717,9837.20638136377,9837.991632053961,9831.495467253299,9838.419950612248,9836.849449231868,9839.562133434343,9844.559183281008,9841.560953373008,9833.20874148644,9829.924965872917,9823.28602821949,9823.85711963054,9831.781012958822,9834.136765029392,9827.426440949585,9816.504317713303,9822.072458971015,9817.932046240921,9810.365085044543,9804.083079523021,9823.14325536673,9817.646500535398,9823.428801072252,9826.855349538537,9822.786323234825,9819.145615489397,9822.42939110292,9797.515528295977,9787.521428602648,9788.877770703884,9787.307269323504,9784.094880136363,9782.524378755981,9782.881310887888,9781.953287344935,9782.452992329601,9783.452402298935,9788.949157130266,9787.521428602648,9787.235882897123,9784.594585121029,9786.165086501409,9791.733227759121,9788.520838571982,9801.870100305212,9796.801664032168,9802.655350995403,9803.654760964737,9794.588684814358,9798.015233280643,9766.89075137856,9760.608745857038,9760.537359430657,9754.326740335517,9753.04178466066,9756.254173847801,9754.041194629992,9752.470693249612,9751.756828985803,9753.184557513421,9758.824085197513,9758.966858050277,9761.251223694466,9753.470103218944,9755.254763878467,9760.894291562561,9761.536769399989,9769.960367712938,9759.038244476656,9757.324970243515,9761.179837268086,9767.74738849513,9764.392226455226,9758.324380212847,9746.759779139138,9758.252993786467,9780.73971809646,9779.169216716078,9778.169806746746,9769.817594860177,9776.385146087223,9777.74148818846,9774.74325828046,9773.244143326463,9771.031164108654,9763.250043633132,9766.462432820274,9755.111991025708,9758.252993786467,9760.394586577895,9758.609925918372,9751.970988264946,9751.54266970666,9771.388096240556,9762.464792942941,9763.678362191416,9758.038834507324,9764.249453602464,9763.321430059514,9770.174526992081,9772.673051915413,9764.035294323323,9766.248273541132,9770.531459123986,9776.956237498269,9776.956237498269,9773.458302605604,9784.73735797379,9785.950927222266,9786.307859354172,9788.235292866457,9790.305499231503,9784.523198694647,9780.596945243697,9775.171576838748,9786.165086501409,9785.237062958457,9790.019953525978,9792.661251302074,9800.656531056737,9804.368625228546,9804.939716639594,9810.293698618163,9793.732047697787,9790.376885657884,9777.241783203794,9777.598715335698,9775.671281823414,9773.315529752843,9770.103140565701,9776.17098680808,9772.673051915413,9774.457712574938,9766.17688711475,9772.38750620989,9772.173346930747,9775.100190412366,9776.813464645507,9780.02585383265,9794.66007124074,9795.873640489215,9800.7993039095,9804.868330213212,9805.296648771497,9819.288388342158,9820.644730443397,9812.792223541495,9829.710806593774,9831.923785811583,9830.99576226863,9824.999302452634,9828.068918787014,9823.357414645872,9828.925555903585,9824.85652959987,9827.06950881768,9827.569213802346,9822.929096087586,9820.359184737874,9822.215231823777,9819.788093326826,9818.431751225588,9816.075999155019,9814.71965705378,9811.507267866638,9827.569213802346,9831.70962653244,9819.145615489397,9825.142075305395,9821.64414041273,9824.285438188825,9835.992812115295,9849.199300995768,9856.480716486623,9851.555053066339,9854.267737268814,9857.408740029574,9858.76508213081,9851.6978259191,9853.26832729948,9849.984551685959,9854.267737268814,9851.198120934434,9849.056528143004,9854.83882867986,9854.553282974337,9851.198120934434,9858.408149998908,9865.975111195285,9864.76154194681,9867.474226149285,9859.978651379288,9863.405199845572,9867.402839722905,9866.831748311857,9878.110803680043,9882.037057130994,9878.896054370232,9883.607558511376,9891.245906134134,9893.387498925562,9891.959770397943,9892.602248235371,9894.172749615751,9891.031746854991,9887.747971241468,9893.744431057466,9892.673634661753,9890.746201149466,9891.7456111188,9890.317882591182,9879.966850765948,9877.968030827282,9866.33204332719,9869.044727529666,9862.762722008145,9871.828798158522,9860.335583511192,9872.328503143188,9864.975701225952,9851.840598771862,9843.060068327008,9848.199891026436,9846.558003219674,9840.632929830057,9836.92083565825,9839.562133434343,9838.848269170534,9840.989861961962,9840.20461127177,9834.636470014058,9830.496057283965,9830.852989415871,9828.854169477203,9836.064198541677,9828.068918787014,9812.50667783597,9808.580424385022,9808.580424385022,9804.368625228546,9799.942666792927,9787.450042176266,9790.376885657884,9785.094290105695,9782.95269731427,9778.52673887865,9783.452402298935,9788.734997851123,9790.805204216169,9784.808744400172,9789.877180673218,9788.092520013694,9790.448272084266,9794.517298387978,9788.949157130266,9791.519068479978,9794.231752682454,9789.520248541312,9782.881310887888,9779.169216716078,9770.103140565701,9778.52673887865,9774.02939401665,9776.884851071889,9782.881310887888,9790.662431363407,9774.529099001318,9772.530279062654,9757.610515949038,9748.544439798661,9734.695473080761,9730.626446777049,9731.126151761715,9731.126151761715,9732.553880289333,9735.552110197332,9734.695473080761,9724.55860053467,9727.628216869049,9732.41110743657,9721.48898420029,9727.628216869049,9727.128511884383,9711.42349808058,9715.778070089815,9722.060075611336,9730.69783320343,9728.270694706478,9720.917892789243,9703.285445473153,9710.923793095912,9712.35152162353,9719.704323540767,9719.847096393529,9720.418187804577,9731.982788878286,9732.625266715715,9727.913762574573,9724.201668402764,9729.627036807715,9730.412287497906,9738.978658663616,9733.053585274,9734.909632359904,9734.62408665438,9728.41346755924,9726.557420473337,9738.40756725257,9735.980428755618,9740.477773617617,9750.329100458184,9737.479543709618,9744.475413494949,9698.859487037536,9679.299606209162,9685.581611730684,9672.87482783488,9679.442379061924,9685.36745245154,9648.603442865364,9653.029401300982,9647.032941484982,9646.176304368413,9658.811701837836,9660.59636249736,9657.52674616298,9662.09547745136,9663.73736525812,9663.309046699835,9670.233530058784,9666.949754445262,9676.586922006687,9662.880728141548,9656.241790488122,9641.750345932795,9641.179254521749,9649.10314785003,9632.541496929654,9612.83884324852,9643.606393018697,9634.897249000225,9637.110228218035,9623.332647926514,9634.468930441939,9625.11730858604,9623.618193632039,9620.619963724039,9625.402854291562,9626.473650687276,9628.044152067658,9617.764506668804,9617.4075745369,9621.33382798785,9620.120258739375,9622.761556515468,9624.260671469467,9616.979255978615,9592.779257435479,9583.855954137862,9597.205215871096,9590.994596775956,9681.155653295065,9670.66184861707,9666.164503755072,9662.09547745136,9653.100787727362,9641.39341380089,9639.608753141367,9664.594002374692,9680.513175457638,9670.876007896213,9677.158013417735,9685.867157436207,9664.736775227453,9675.516125610973,9678.799901224496,9680.084856899353,9676.444149153926,9675.016420626307,9681.369812574208,9675.658898463735,9676.372762727544,9686.866567405541,9690.150343019062,9688.508455212303,9690.65004800373,9693.719664338108,9687.58043166935,9683.225859660113,9681.726744706113,9679.156833356401,9674.945034199925,9675.30196633183,9681.012880442304,9677.58633197602,9686.79518097916,9690.507275150969,9691.57807154668,9684.58220176135,9681.012880442304,9675.801671316496,9682.012290411638,9674.159783509735,9677.443559123258,9672.87482783488,9678.014650534305,9686.723794552778,9682.226449690781,9678.514355518972,9679.22821978278,9670.876007896213,9685.010520319636,9697.64591778906,9699.073646316678,9695.432938571252,9688.865387344205,9689.507865181635,9692.720254368776,9688.151523080396,9690.0075701663,9691.149752988396,9692.720254368776,9690.72143443011,9692.720254368776,9698.788100611155,9700.572761270678,9695.932643555918,9693.362732206206,9694.5049150283,9680.72733473678,9690.864207282872,9704.49901472163,9704.927333279915,9704.784560427153,9710.70963381677,9713.993409430293,9733.83883596419,9725.772169783146,9731.982788878286,9737.265384430473,9733.053585274,9732.839425994858,9729.91258251324,9733.553290258667,9733.267744553143,9726.486034046955,9731.197538188095,9729.19871824943,9734.981018786286,9740.906092175901,9742.26243427714,9745.403437037901,9745.189277758758,9741.54857001333,9740.977478602283,9748.187507666757,9772.887211194557,9778.52673887865,9780.596945243697,9766.391046393892,9785.808154369504,9784.951517252934,9778.027033893984,9770.81700482951,9794.445911961597,9793.80343412417,9791.162136348075,9797.943846854263,9800.014053219309,9797.872460427881,9790.234112805121,9793.94620697693,9791.376295627217,9788.734997851123,9781.953287344935,9784.309039415506,9793.589274845026,9788.306679292837,9797.08720973769,9793.80343412417,9792.518478449312,9780.09724025903,9783.523788725315,9790.87659064255,9793.94620697693,9797.586914722358,9802.227032437118,9801.441781746928,9799.228802529118,9796.23057262112,9789.734407820457,9793.660661271406,9794.517298387978,9793.94620697693,9800.299598924834,9803.22644240645,9810.293698618163,9811.007562881972,9812.221132130448,9812.363904983209,9801.798713878832,9809.508447927972,9801.870100305212,9796.516118326645,9784.951517252934,9780.240013111792,9778.740898157794,9768.604025611701,9773.95800759027,9781.310809507506,9785.308449384838,9789.020543556646,9783.309629446172,9786.09370007503,9784.665971547409,9787.378655749884,9787.664201455409,9785.165676532075,9785.879540795884,9790.234112805121,9787.021723617981,9790.947977068932,9780.525558817317,9787.878360734552,9805.796353756165,9812.792223541495,9806.010513035306,9804.440011654928,9804.654170934069,9824.713756747109,9826.712576685777,9826.569803833014,9839.633519860723,9846.129684661388,9839.990451992628,9831.923785811583,9831.852399385201,9834.993402145963,9833.351514339201,9834.993402145963,9837.92024562758,9836.849449231868,9833.99399217663,9837.20638136377,9837.277767790152,9838.419950612248,9840.20461127177,9846.27245751415,9866.760361885476,9875.826438035854,9889.46124547461,9883.750331364135,9889.675404753752,9878.396349385566,9887.747971241468,9886.32024271385,9885.53499202366,9887.462425535945,9885.320832744515,9883.036467100326,9887.533811962325,9890.175109738419,9884.392809201565,9892.316702529848,9896.028796701656,9896.314342407179,9894.672454600419,9890.532041870325,9887.533811962325,9889.104313342707,9886.177469861088,9891.531451839657,9887.605198388706,9886.463015566611,9890.746201149466,9892.602248235371,9887.89074409423,9872.828208127854,9860.12142423205,9875.041187345663,9856.33794363386,9851.483666639957,9857.694285735099,9858.55092285167,9861.334993480526,9856.26655720748,9852.768622314814,9855.338533664526,9856.409330060242,9859.40755996824,9861.620539186048,9865.975111195285,9868.830568250523,9868.901954676903,9871.971571011283,9872.685435275092,9874.398709508236,9868.045317560332,9875.755051609473,9877.182780137091,9877.611098695375,9878.681895091091,9881.894284278233,9877.539712268996,9879.609918634042,9875.826438035854,9874.82702806652,9873.542072391663,9874.255936655472,9874.755641640138,9874.184550229093,9878.967440796614,9874.969800919282,9872.828208127854,9877.254166563473,9870.615228910045,9875.041187345663,9879.966850765948,9878.467735811948,9867.616999002048,9862.334403449857,9868.045317560332,9863.262426992811,9862.191630597095,9862.619949155382,9866.40342975357,9862.048857744336,9846.486616793292,9848.913755290245,9841.489566946628,9841.70372622577,9838.919655596914,9839.276587728818,9836.706676379104,9836.206971394438,9841.204021241105,9840.632929830057,9836.778062805486,9831.852399385201,9834.636470014058,9835.42172070425,9838.70549631777,9834.850629293202,9845.201661118435,9849.913165259577,9849.484846701293,9847.84295889453,9850.912575228911,9850.198710965102,9841.77511265215,9842.488976915962,9836.849449231868,9830.210511578442,9827.355054523205,9827.71198665511,9824.499597467968,9827.71198665511,9829.782193020155,9824.713756747109,9828.354464492537,9824.285438188825,9820.930276148922,9816.004612728637,9811.507267866638,9815.219362038446,9816.718476992446,9813.93440636359,9827.355054523205,9841.418180520246,9835.635879983392,9835.778652836154,9831.138535121392,9815.219362038446,9827.06950881768,9819.217001915778,9815.790453449494,9798.657711118072,9807.00992300464,9812.863609967875,9800.727917483118,9802.441191716262,9802.798123848166,9801.65594102607,9803.22644240645,9810.436471470925,9804.225852375785,9805.43942162426,9800.228212498452,9802.084259584355,9800.942076762261,9801.65594102607,9796.3019590475,9803.22644240645,9810.79340360283,9817.432341256255,9816.075999155019,9802.583964569021,9796.658891179406,9782.38160590322,9782.452992329601,9773.95800759027,9777.313169630175,9779.597535274363,9776.884851071889,9772.530279062654,9772.815824768175,9771.173936961415,9776.17098680808,9776.313759660841,9778.169806746746,9771.245323387795,9771.959187651604,9764.749158587132,9759.252403755801,9758.681312344754,9764.820545013514,9768.032934200653,9773.386916179223,9771.673641946081,9771.316709814177,9774.67187185408,9773.1013704737,9780.953877375601,9852.55446303567,9853.196940873098,9853.339713725862,9861.120834201383,9853.411100152241,9848.199891026436,9854.339123695196,9845.130274692056,9846.129684661388,9840.989861961962,9833.137355060058,9830.638830136726,9834.850629293202,9843.060068327008,9843.345614032532,9842.988681900626,9848.913755290245,9837.563313495677,9837.491927069295,9831.352694400537,9828.354464492537,9848.842368863863,9838.277177759486,9841.275407667486,9836.706676379104,9827.497827375964,9826.641190259395,9820.359184737874,9806.867150151878,9802.012873157975,9801.441781746928,9803.08366955369,9803.440601685594,9802.726737421784,9821.358594707206,9814.791043480162,9809.651220780734,9800.442371777594,9804.154465949403,9810.365085044543,9806.081899461687,9803.29782883283,9809.008742943306,9820.501957590635,9820.07363903235,9826.498417406634,9820.002252605967,9821.215821854445,9819.788093326826,9822.143845397397,9819.002842636637,9815.43352131759,9820.573344017015,9819.788093326826,9819.217001915778,9818.788683357492,9821.215821854445,9818.288978372828,9814.576884201018,9813.506087805305,9808.152105826734,9804.79694378683,9798.372165412547,9803.511988111975,9809.29428864883,9801.65594102607,9795.802254062834,9793.16095628674,9779.668921700744,9785.522608663981,9793.232342713121,9797.301369016834,9806.724377299115,9810.864790029209,9832.352104369867,9836.135584968059,9833.137355060058,9833.422900765583,9834.136765029392,9831.63824010606,9834.279537882154,9837.706086348438,9838.49133703863,9838.063018480343,9846.772162498817,9840.775702682819,9838.134404906725,9838.134404906725,9837.92024562758,9834.493697161297,9834.350924308535,9836.135584968059,9850.198710965102,9845.415820397578,9837.349154216534,9839.633519860723,9843.488386885292,9845.701366103101,9850.912575228911,9850.198710965102,9846.486616793292,9843.559773311674,9843.631159738055,9840.91847553558,9839.919065566248,9840.91847553558,9841.132634814723,9833.92260575025,9836.421130673583,9834.06537860301,9837.277767790152,9834.850629293202,9828.211691639775,9828.854169477203,9818.788683357492,9806.367445167212,9808.009332973972,9801.798713878832,9806.510218019974,9812.578064262352,9841.989271931296,9840.418770550914,9840.704316256437,9837.277767790152,9842.203431210437,9846.058298235008,9837.8488592012,9836.635289952725,9836.92083565825,9837.277767790152,9848.199891026436,9843.702546164435,9854.267737268814,9851.555053066339,9848.128504600054,9852.840008741196,9857.622899308717,9856.623489339383,9860.12142423205,9856.623489339383,9852.126144477386,9852.197530903766,9858.76508213081,9861.334993480526,9868.830568250523,9864.547382667666,9864.975701225952,9865.47540621062,9866.26065690081,9869.687205367094,9866.47481617995,9863.19104056643,9866.831748311857,9867.90254470757,9861.76331203881,9860.906674922238,9855.909625075576,9853.482486578623,9854.624669400717,9850.055938112338,9857.337353603192,9765.819954982844,9773.315529752843,9763.17865720675,9748.47305337228,9751.970988264946,9729.19871824943,9756.040014568658,9761.536769399989,9756.254173847801,9758.252993786467,9752.32792039685,9748.901371930566,9756.896651685229,9760.965677988941,9758.46715306561,9754.112581056374,9750.257714031804,9746.26007415447,9741.762729292474,9738.907272237237,9736.194588034761,9741.762729292474,9736.694293019427,9747.188097697423,9739.478363648283,9768.746798464463,9769.246503449129,9766.462432820274,9772.030574077986,9781.168036654744,9776.028213955318,9787.521428602648,9797.658301148738,9799.3001889555,9793.08956986036,9793.446501992263,9791.090749921694,9796.3019590475,9791.162136348075,9791.162136348075,9792.661251302074,9793.589274845026,9790.234112805121,9785.736767943125,9783.666561578078,9782.881310887888,9783.666561578078,9789.020543556646,9783.024083740649,9802.227032437118,9792.090159891026,9798.44355183893,9787.521428602648,9792.946797007597,9793.232342713121,9783.095470167029,9791.162136348075,9778.955057436935,9779.454762421603,9782.31021947684,9789.306089262169,9789.234702835789,9787.450042176266,9787.378655749884,9794.945616946263,9798.729097544452,9800.513758203975,9801.51316817331,9801.941486731594,9799.585734661025,9807.366855136544,9803.440601685594,9809.508447927972,9813.506087805305,9821.429981133588,9819.859479753206,9808.080719400354,9850.12732453872,9869.473046087951,9849.41346027491,9864.618769094048,9853.768032284148,9844.202251149101,9838.70549631777,9837.06360851101,9839.633519860723,9833.351514339201,9825.356234584538,9829.568033741012,9832.28071794349,9836.135584968059,9837.92024562758,9831.70962653244,9832.42349079625,9832.637650075392,9848.128504600054,9846.34384394053,9843.845319017199,9841.489566946628,9856.694875765765,9855.838238649194,9865.689565489762,9867.11729401738,9860.05003780567,9868.116703986714,9861.76331203881,9854.76744225348,9873.042367406997,9871.257706747474,9866.546202606332,9866.831748311857,9869.972751072617,9872.471275995951,9876.683075152425,9882.608148542042,9880.466555750614,9877.753871548139,9887.605198388706,9891.602838266039,9882.251216410137,9881.75151142547,9887.10549340404,9897.456525229274,9890.317882591182,9876.540302299663,9873.756231670806,9873.756231670806,9863.262426992811,9857.337353603192,9859.621719247383,9853.625259431385,9851.126734508052,9848.770982437483,9854.267737268814,9851.340893787195,9856.33794363386,9849.484846701293,9850.769802376148,9850.98396165529,9857.622899308717,9858.265377146145,9865.047087652332,9860.12142423205,9853.553873005005,9858.76508213081,9854.553282974337,9865.332633357857,9862.691335581763,9859.33617354186,9856.480716486623,9874.398709508236,9871.329093173854,9868.330863265857,9860.835288495859,9859.693105673763,9860.621129216717,9856.837648618526,9856.909035044908,9851.055348081672,9861.834698465193,9858.479536425288,9854.553282974337,9856.123784354717,9853.553873005005,9854.624669400717,9854.196350842432,9846.700776072435,9846.558003219674,9846.129684661388,9845.48720682396,9836.99222208463,9845.701366103101,9840.490156977296,9867.18868044376,9872.828208127854,9875.969210888616,9882.037057130994,9890.532041870325,9885.463605597279,9891.531451839657,9890.603428296707,9887.676584815088,9887.533811962325,9891.103133281373,9887.81935766785,9887.10549340404,9875.969210888616,9876.540302299663,9874.327323081854,9875.255346624806,9876.183370167757,9875.398119477568,9880.823487882519,9859.264787115479,9868.188090413094,9875.68366518309,9869.758591793476,9866.046497621666,9868.188090413094,9877.04000728433,9867.331453296523,9878.110803680043,9877.753871548139,9884.74974133347,9878.896054370232,9878.253576532805,9878.681895091091,9875.54089233033,9872.471275995951,9874.82702806652,9877.04000728433,9877.539712268996,9881.251806440803,9883.036467100326,9878.967440796614,9879.681305060423,9893.530271778323,9893.458885351942,9900.811687269177,9911.376878373556,9917.15917891041,9916.945019631268,9903.809917177177,9898.741480904131,9911.305491947174,9905.523191410319,9912.875993327554,9910.163309125079,9913.018766180316,9905.023486425653,9907.80755705451,9908.949739876603,9907.307852069842,9907.522011348985,9908.592807744699,9915.088972545362,9918.872453143553,9917.587497468696,9920.15740881841,9927.724370014786,9926.510800766311,9925.368617944216,9936.43351403326,9925.72555007612,9937.21876472345,9935.505490490308,9947.92672868059,9946.784545858494,9944.357407361542,9947.855342254208,9948.212274386115,9948.854752223542,9942.858292407544,9938.71787967745,9938.360947545545,9942.001655290973,9943.786315950496,9938.575106824688,9937.361537576211,9937.14737829707,9937.07599187069,9936.290741180499,9940.359767484211,9935.077171932022,9931.222304907453,9935.148558358404,9941.216404600782,9938.07540184002,9939.788676073164,9945.285430904496,9951.06773144135,9948.711979370779,9948.426433665256,9952.781005674493,9954.13734777573,9934.577466947356,9932.935579140596,9923.441184431931,9925.582777223359,9927.367437882884,9927.510210735643,9925.582777223359,9918.872453143553,9926.011095781645,9921.156818787742,9911.01994624165,9904.309622161843,9902.881893634225,9929.937349232596,9934.577466947356,9938.932038956593,9941.287791027164,9922.013455904313,9902.524961502319,9871.543252452997,9872.185730290426,9869.258886808808,9872.685435275092,9874.470095934616,9872.756821701472,9869.615818940712,9873.470685965282,9874.04177737633,9872.257116716806,9874.113163802711,9870.044137498999,9862.548562729002,9864.475996241286,9870.972161041951,9866.617589032714,9866.33204332719,9840.418770550914,9828.640010198062,9834.565083587677,9838.348564185868,9832.709036501774,9818.860069783874,9812.578064262352,9827.640600228728,9822.35800467654,9822.42939110292,9822.857709661206,9818.003432667303,9812.934996394257,9815.50490774397,9813.291928526161,9807.581014415688,9814.219952069114,9808.366265105878,9811.864199998543,9810.864790029209,9805.867740182546,9808.009332973972,9806.724377299115,9815.005202759303,9816.861249845208,9819.716706900446,9832.137945090726,9836.563903526343,9834.636470014058,9833.708446471106,9840.989861961962,9839.990451992628,9831.067148695012,9836.849449231868,9840.91847553558,9846.772162498817,9847.05770820434,9846.558003219674,9843.845319017199,9843.202841179771,9845.201661118435,9844.987501839292,9849.627619554054,9851.412280213577,9841.489566946628,9846.27245751415,9840.347384124532,9840.20461127177,9846.129684661388,9849.841778833195,9837.634699922059,9838.70549631777,9842.703136195103,9845.415820397578,9852.697235888432,9847.486026762626,9852.625849462052,9846.843548925199,9849.913165259577,9846.914935351577,9847.05770820434,9852.911395167575,9853.482486578623,9848.342663879195,9852.911395167575,9852.268917330148,9845.55859325034,9842.845909047865,9842.774522621483,9839.990451992628,9841.204021241105,9839.633519860723,9834.136765029392,9823.9998924833,9823.21464179311,9818.931456210255,9809.651220780734,9804.654170934069,9796.23057262112,9790.448272084266,9800.15682607207,9797.229982590454,9794.160366256072,9801.870100305212,9798.372165412547,9796.658891179406,9797.8010740015,9797.872460427881,9799.799893940166,9798.800483970834,9804.011693096641,9802.084259584355,9805.296648771497,9807.438241562924,9808.437651532258,9802.655350995403,9809.865380059877,9790.519658510646,9801.299008894166,9799.157416102738,9796.730277605788,9779.097830289698,9752.185147544089,9742.690752835426,9726.20048834143,9726.842966178858,9720.346801378195,9717.491344322958,9716.491934353624,9718.41936786591,9722.345621316861,9718.847686424197,9723.416417712575,9717.348571470196,9724.701373387432,9721.988689184956,9727.770989721812,9730.69783320343,9730.983378908952,9730.69783320343,9737.765089415141,9729.769809660476,9738.550340105332,9729.769809660476,9725.129691945718,9728.270694706478,9747.259484123804,9752.613466102373,9764.820545013514,9764.820545013514,9762.464792942941,9766.962137804941,9770.602845550367,9769.389276301892,9766.248273541132,9762.536179369323,9766.605205673035,9768.746798464463,9780.668331670078,9782.809924461506,9784.808744400172,9786.450632206934,9790.376885657884,9793.446501992263,9790.733817789787,9796.87305045855,9788.949157130266,9785.950927222266,9783.809334430838,9797.372755443215,9800.585144630357,9790.947977068932,9776.670691792748,9786.593405059695,9785.665381516743,9781.524968786649,9790.805204216169,9789.234702835789,9785.736767943125,9782.096060197697,9787.592815029027,9788.378065719218,9781.382195933887,9779.883080979887,9785.665381516743,9788.734997851123,9791.019363495312,9787.235882897123,9792.44709202293,9797.015823311309,9796.373345473881,9795.30254907817,9790.448272084266,9790.162726378741,9793.80343412417,9794.303139108835,9807.79517369483,9794.303139108835,9805.653580903403,9799.799893940166,9798.372165412547,9798.514938265309,9795.159776225406,9793.732047697787,9795.017003372644,9794.017593403312,9792.661251302074,9793.517888418644,9793.16095628674,9792.732637728455,9808.865970090543,9803.22644240645,9810.864790029209,9811.721427145781,9811.6500407194,9809.722607207115,9814.6482706274,9822.215231823777,9843.98809186996,9846.20107108777,9839.919065566248,9814.862429906543,9816.575704139685,9815.50490774397,9824.999302452634,9820.85888972254,9818.717296931112,9820.07363903235,9820.216411885112,9819.431161194922,9813.077769247018,9823.571573925015,9821.287208280824,9819.217001915778,9817.360954829874,9817.218181977112,9827.569213802346,9830.852989415871,9838.277177759486,9834.06537860301,9820.85888972254,9818.146205520065,9810.579244323686,9785.665381516743,9778.383966025887,9778.812284584175,9791.519068479978,9790.805204216169,9796.944436884929,9794.374525535215,9791.162136348075,9792.018773464646,9792.732637728455,9796.516118326645,9795.58809478369,9795.873640489215,9791.876000611885,9795.51670835731,9788.806384277503,9786.522018633314,9787.806974308172,9806.724377299115,9804.939716639594,9801.941486731594,9801.227622467784,9798.729097544452,9805.296648771497,9809.22290222245,9815.005202759303,9820.216411885112,9818.931456210255,9814.362724921875,9820.85888972254,9822.929096087586,9820.287798311492,9789.877180673218,9788.163906440075,9786.23647292779,9792.161546317408,9799.157416102738,9802.655350995403,9800.513758203975,9797.301369016834,9794.588684814358,9793.446501992263,9794.731457667122,9789.234702835789,9790.09133995236,9779.740308127126,9781.310809507506,9790.448272084266,9807.652400842067,9820.85888972254,9817.218181977112,9817.289568403494,9823.571573925015,9822.500777529302,9821.858299691874,9824.285438188825,9820.930276148922,9821.786913265492,9823.785733204159,9822.286618250158,9816.432931286921,9817.717886961778,9817.86065981454,9813.363314952543,9806.367445167212,9801.441781746928,9790.019953525978,9790.162726378741,9795.017003372644,9782.024673771315,9764.606385734369,9773.88662116389,9776.456532513603,9786.23647292779,9792.37570559655,9793.94620697693,9792.589864875694,9785.237062958457,9778.955057436935,9780.596945243697,9783.595175151697,9781.524968786649,9778.098420320366,9774.814644706841,9761.67954225275,9761.465382973609,9763.321430059514,9759.109630903038,9757.467743096277,9761.322610120847,9775.956827528937,9769.603435581035,9765.748568556464,9772.31611978351,9768.746798464463,9777.384556056557,9780.953877375601,9778.52673887865,9755.825855289517,9754.469513188278,9749.829395473516,9755.968628142276,9763.321430059514,9766.105500688369,9765.034704292655,9767.961547774274,9763.749748617798,9770.602845550367,9770.460072697606,9775.171576838748,9774.457712574938,9772.530279062654,9767.604615642369,9738.122021547046,9729.698423234096,9736.337360887523,9754.469513188278,9742.119661424376,9745.831755596186,9752.684852528755,9741.263024307807,9715.278365105149,9698.859487037536,9687.937363801253,9690.935593709253,9678.942674077256,9689.86479731354,9694.076596470015,9695.004620012965,9692.22054938411,9694.147982896395,9695.504324997633,9693.719664338108,9698.145622773727,9700.572761270678,9698.359782052868,9697.003439951632,9689.722024460778,9694.5049150283,9698.074236347346,9685.724384583445,9665.165093785738,9672.303736423832,9677.58633197602,9676.015830595641,9694.219369322775,9722.559780596004,9724.701373387432,9724.201668402764,9725.34385122486,9727.770989721812,9731.48308389362,9713.85063657753,9722.131462037718,9717.705503602101,9728.41346755924,9731.268924614476,9729.412877528574,9730.198128218764,9732.553880289333,9726.557420473337,9726.771579752478,9717.134412191053,9711.066565948675,9718.990459276958,9718.49075429229,9714.278955135816,9716.420547927244,9715.706683663433,9711.352111654198,9712.494294476293,9713.85063657753,9715.34975153153,9716.563320780006,9714.136182283055,9715.492524384292,9716.777480059149,9714.421727988578,9715.135592252387,9718.133822160386,9723.202258433434,9723.345031286193,9724.487214108289,9729.484263954955,9720.632347083718,9678.014650534305,9661.452999613932,9680.870107589542,9669.234120089452,9666.87836801888,9670.162143632404,9664.665388801071,9679.370992635544,9690.0075701663,9704.927333279915,9704.784560427153,9712.065975918009,9711.851816638864,9710.424088111246,9705.427038264581,9703.285445473153,9705.712583970106,9707.925563187915,9712.637067329055,9720.632347083718,9727.485444016287,9728.841786117526,9727.057125458003,9730.055355366001,9736.765679445807,9727.842376148192,9724.844146240193,9728.484853985621,9738.40756725257,9729.27010467581,9724.915532666573,9727.628216869049,9738.835885810855,9759.252403755801,9756.96803811161,9746.97393841828,9751.257124001137,9758.966858050277,9765.534409277323,9757.967448080944,9766.17688711475,9765.891341409226,9779.311989568841,9789.306089262169,9785.808154369504,9779.311989568841,9773.74384831113,9775.314349691509,9771.173936961415,9782.452992329601,9790.805204216169,9789.448862114932,9787.73558788179,9792.44709202293,9797.8010740015,9778.383966025887,9787.592815029027,9779.954467406269,9782.738538035124,9790.805204216169,9788.59222499836,9787.949747160932,9788.520838571982,9784.880130826554,9789.877180673218,9794.802844093501,9797.158596164072,9791.162136348075,9795.017003372644,9798.158006133406,9800.727917483118,9812.863609967875,9803.08366955369,9786.736177912457,9780.596945243697,9788.949157130266,9788.021133587314,9788.378065719218,9772.530279062654,9766.319659967512,9757.824675228181,9779.311989568841,9775.742668249793,9775.45712254427,9787.664201455409,9790.448272084266,9782.738538035124,9777.598715335698,9783.9521072836,9781.524968786649,9787.949747160932,9786.9503371916,9788.877770703884,9792.232932743787,9789.091929983028,9792.518478449312,9775.671281823414,9774.886031133223,9783.381015872554,9783.595175151697,9771.031164108654,9772.101960504366,9782.096060197697,9766.962137804941,9775.028803985984,9777.812874614841,9774.886031133223,9765.177477145417,9770.245913418463,9768.175707053417,9766.248273541132,9767.890161347892,9766.533819246653,9766.676592099417,9773.815234737509,9763.749748617798,9758.395766639229,9758.53853949199,9758.110220933704,9745.903142022567,9756.325560274183,9758.53853949199,9749.25830406247,9752.827625381517,9751.47128328028,9752.542079675992,9754.041194629992,9746.688392712756,9744.332640642186,9755.540309583992,9744.475413494949,9743.904322083901,9744.118481363044,9743.547389951995,9741.61995643971,9741.834115718855,9741.120251455044,9738.693112958092,9742.904912114567,9742.833525688186,9746.545619859995,9745.046504905995,9748.758599077804,9751.042964721993,9716.991639338292,9707.996949614295,9706.926153218581,9705.926743249247,9701.50078481363,9712.065975918009,9709.353291715533,9722.131462037718,9731.197538188095,9742.405207129901,9742.976298540949,9735.266564491809,9731.911402451906,9732.768039568477,9731.768629599143,9730.840606056192,9732.054175304667,9728.342081132858,9724.772759813812,9720.06125567267,9718.49075429229,9715.778070089815,9720.132642099052,9726.129101915049,9727.485444016287,9728.484853985621,9727.69960329543,9726.985739031621,9718.704913571433,9718.062435734006,9723.130872007052,9711.780430212484,9707.854176761533,9707.140312497724,9701.143852681726,9704.49901472163,9708.853586730866,9709.424678141913,9710.352701684866,9710.352701684866,9711.066565948675,9711.137952375055,9713.636477298387,9707.425858203247,9705.498424690963,9710.209928832102,9707.140312497724,9705.070106132676,9715.421137957912,9703.214059046772,9707.068926071343,9707.782790335152,9704.64178757439,9696.432348540584,9724.772759813812,9719.2046185561,9692.434708663253,9689.507865181635,9688.936773770587,9694.362142175538,9695.29016571849,9700.572761270678,9699.858897006869,9704.57040114801,9708.425268172581,9707.64001748239,9709.496064568293,9711.923203065246,9708.853586730866,9707.711403908772,9703.570991178678,9706.783380365818,9709.13913243639,9703.356831899535,9711.209338801436,9724.487214108289,9724.273054829146,9726.343261194193,9726.486034046955,9716.991639338292,9714.278955135816,9712.922613034578,9717.277185043815,9716.420547927244,9719.276004982481,9717.063025764672,9717.134412191053,9718.41936786591,9720.204028525433,9721.060665642004,9727.913762574573,9729.555650381335,9727.199898310764,9732.125561731049,9739.692522927426,9736.551520166664,9729.769809660476,9718.062435734006,9697.64591778906,9704.64178757439,9710.281315258484,9697.71730421544,9680.870107589542,9660.881908202882,9675.444739184592,9676.015830595641,9684.867747466875,9676.015830595641,9677.6577184024,9672.803441408498,9671.732645012784,9674.659488494402,9671.946804291925,9677.015240564971,9672.446509276593,9666.592822313356,9666.450049460595,9658.240610426788,9657.241200457456,9645.819372236507,9640.179844552415,9640.965095242604,9627.116128524705,9635.182794705748,9633.969225457273,9633.68367975175,9623.404034352896,9625.402854291562,9640.53677668432,9650.60226280403,9640.6081631107,9638.32379746651,9592.993416714622,9616.550937420327,9617.050642404995,9617.4075745369,9616.265391714804,9616.836483125851,9623.332647926514,9625.18869501242,9623.903739337564,9622.690170089087,9632.541496929654,9628.258311346799,9622.476010809945,9619.263621622802,9626.116718555371,9612.76745682214,9603.986926377283,9605.27188205214,9576.288992941485,9590.066573233004,9590.423505364908,9582.642384889386,9589.209936116433,9587.139729751387,9583.284862726816,9581.214656361768,9584.783977680816,9586.640024766719,9587.353889030528,9591.137369628717,9591.708461039765,9587.49666188329,9587.282502604146,9586.283092634814,9589.995186806622,9584.926750533577,9578.28781288015,9581.785747772816,9578.644745012056,9580.215246392436,9571.434715947582,9569.8642145672,9554.159200763397,9559.299023462825,9567.151530364725,9576.931470778913,9569.507282435297,9571.863034505868,9577.788107895485,9575.432355824913,9580.286632818816,9577.50256218996,9573.433535886248,9574.575718708344,9574.218786576437,9577.002857205294,9577.50256218996,9579.001677143959,9579.572768555006,9582.570998463007,9576.788697926151,9566.294893248156,9567.43707607025,9570.863624536534,9569.150350303393,9578.359199306531,9568.579258892345,9558.585159199016,9582.570998463007,9583.57040843234,9581.428815640911,9577.002857205294,9576.431765794247,9577.359789337199,9576.931470778913,9575.07542369301,9573.933240870914,9567.008757511965,9567.080143938345,9566.009347542631,9569.364509582534,9566.223506821774,9564.724391867776,9566.509052527297,9564.510232588631,9543.522623232639,9522.89194600855,9529.959202220263,9519.965102526932,9525.676016637408,9519.179851836743,9512.540914183317,9511.041799229317,9509.042979290653,9498.549174612655,9494.480148308943,9488.697847772088,9491.339145548183,9492.267169091134,9495.693717557418,9492.981033354943,9491.624691253706,9489.340325609515,9489.197552756756,9492.624101223038,9496.336195394846,9493.55212476599,9498.19224248075,9497.478378216942,9510.327934965508,9506.6158407937,9496.193422542086,9503.403451606559,9508.043569321319,9496.193422542086,9501.11908596237,9507.829410042177,9512.398141330556,9505.75920367713,9510.327934965508,9510.39932139189,9513.825869858174,9515.03943910665,9511.827049919508,9515.18221195941,9520.607580364362,9523.034718861314,9520.4648075116,9523.248878140457,9522.535013876648,9521.32144462817,9516.824099766172,9522.963332434932,9538.596959812356,9535.527343477976,9534.171001376739,9543.808168938163,9549.519083048637,9555.08722430635,9538.025868401308,9550.875425149876,9553.159790794065,9565.295483278822,9577.788107895485,9572.291353064153,9575.07542369301,9576.788697926151,9571.220556668439,9577.930880748247,9570.57807883101,9567.43707607025,9565.009937573297,9562.79695835549,9561.512002680633,9563.296663340156,9559.227637036443,9567.508462496631,9551.589289413685,9547.734422389114,9556.300793554825,9564.081914030347,9560.726751990444,9571.3633295212,9584.498431975291,9586.068933355671,9593.921440257574,9599.703740794428,9598.061852987668,9590.566278217671,9594.49253166862,9592.208166024431,9585.997546929291,9578.644745012056,9581.428815640911,9585.783387650148,9583.927340564243,9582.78515774215,9586.854184045862,9588.99577683729,9578.858904291199,9590.066573233004,9602.13087929138,9601.702560733096,9592.493711729956,9603.70138067176,9607.48486126995,9602.84474355519,9596.491351607287,9583.64179485872,9589.495481821956,9605.486041331284,9606.485451300618,9606.485451300618,9607.342088417188,9602.987516407951,9599.632354368048,9601.060082895667,9595.848873769859,9595.777487343477,9594.635304521384,9598.061852987668,9596.562738033668,9596.63412446005,9587.568048309671,9567.722621775774,9566.080733969013,9568.703571215243],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\",\"size\":10},\"mode\":\"markers\",\"name\":\"Buy\",\"x\":[2300],\"y\":[9568.703571215243],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Simulaci\\u00f3n de Trading - Retorno: -4.31%\"},\"xaxis\":{\"title\":{\"text\":\"Tiempo\"}},\"yaxis\":{\"title\":{\"text\":\"Valor del Portfolio\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c55cbe40-d962-40e0-870e-5d55eb1c09c8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo y recursos guardados exitosamente!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =============================================\n",
        "# ANÁLISIS EXPLORATORIO Y FEATURE ENGINEERING\n",
        "# =============================================\n",
        "\n",
        "import ta\n",
        "from ta import add_all_ta_features\n",
        "from ta.utils import dropna\n",
        "\n",
        "class AdvancedFeatureEngineer:\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "\n",
        "    def add_price_features(self):\n",
        "        \"\"\"Características basadas en precio\"\"\"\n",
        "        df = self.df\n",
        "\n",
        "        # Returns y volatilidad\n",
        "        df['returns'] = df['close'].pct_change()\n",
        "        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))\n",
        "        df['volatility'] = df['returns'].rolling(window=20).std()\n",
        "        df['price_range'] = (df['high'] - df['low']) / df['close']\n",
        "        df['body_size'] = abs(df['close'] - df['open']) / df['close']\n",
        "\n",
        "        # Medias móviles\n",
        "        for window in [5, 10, 20, 50]:\n",
        "            df[f'sma_{window}'] = df['close'].rolling(window=window).mean()\n",
        "            df[f'ema_{window}'] = df['close'].ewm(span=window).mean()\n",
        "            df[f'price_vs_sma_{window}'] = df['close'] / df[f'sma_{window}'] - 1\n",
        "\n",
        "        return df\n",
        "\n",
        "    def add_technical_indicators(self):\n",
        "        \"\"\"Indicadores técnicos avanzados\"\"\"\n",
        "        df = self.df\n",
        "\n",
        "        # RSI\n",
        "        df['rsi'] = ta.momentum.RSIIndicator(df['close']).rsi()\n",
        "\n",
        "        # MACD\n",
        "        macd = ta.trend.MACD(df['close'])\n",
        "        df['macd'] = macd.macd()\n",
        "        df['macd_signal'] = macd.macd_signal()\n",
        "        df['macd_histogram'] = macd.macd_diff()\n",
        "\n",
        "        # Bollinger Bands\n",
        "        bollinger = ta.volatility.BollingerBands(df['close'])\n",
        "        df['bb_upper'] = bollinger.bollinger_hband()\n",
        "        df['bb_lower'] = bollinger.bollinger_lband()\n",
        "        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['close']\n",
        "        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
        "\n",
        "        # Ichimoku Cloud\n",
        "        ichimoku = ta.trend.IchimokuIndicator(df['high'], df['low'])\n",
        "        df['ichimoku_a'] = ichimoku.ichimoku_a()\n",
        "        df['ichimoku_b'] = ichimoku.ichimoku_b()\n",
        "        df['ichimoku_base'] = ichimoku.ichimoku_base_line()\n",
        "        df['ichimoku_conversion'] = ichimoku.ichimoku_conversion_line()\n",
        "\n",
        "        # Volumen (aunque no tenemos volumen, usamos rangos de precio como proxy)\n",
        "        df['atr'] = ta.volatility.AverageTrueRange(df['high'], df['low'], df['close']).average_true_range()\n",
        "\n",
        "        # Stochastic\n",
        "        stoch = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close'])\n",
        "        df['stoch_k'] = stoch.stoch()\n",
        "        df['stoch_d'] = stoch.stoch_signal()\n",
        "\n",
        "        # ADX\n",
        "        df['adx'] = ta.trend.ADXIndicator(df['high'], df['low'], df['close']).adx()\n",
        "\n",
        "        return df\n",
        "\n",
        "    def add_time_features(self):\n",
        "        \"\"\"Características temporales\"\"\"\n",
        "        df = self.df\n",
        "\n",
        "        df['hour'] = df['date'].dt.hour\n",
        "        df['day_of_week'] = df['date'].dt.dayofweek\n",
        "        df['day_of_month'] = df['date'].dt.day\n",
        "        df['month'] = df['date'].dt.month\n",
        "        df['week_of_year'] = df['date'].dt.isocalendar().week\n",
        "\n",
        "        # Ciclos temporales\n",
        "        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def add_statistical_features(self):\n",
        "        \"\"\"Características estadísticas avanzadas\"\"\"\n",
        "        df = self.df\n",
        "\n",
        "        # Rolling statistics\n",
        "        for window in [10, 20, 50]:\n",
        "            df[f'rolling_mean_{window}'] = df['close'].rolling(window).mean()\n",
        "            df[f'rolling_std_{window}'] = df['close'].rolling(window).std()\n",
        "            df[f'rolling_skew_{window}'] = df['close'].rolling(window).skew()\n",
        "            df[f'rolling_kurt_{window}'] = df['close'].rolling(window).kurt()\n",
        "\n",
        "        # Z-score\n",
        "            df[f'z_score_{window}'] = (df['close'] - df[f'rolling_mean_{window}']) / df[f'rolling_std_{window}']\n",
        "\n",
        "        # Hurst Exponent (simplificado)\n",
        "        def hurst_exponent(ts):\n",
        "            lags = range(2, 20)\n",
        "            tau = [np.std(np.subtract(ts[lag:], ts[:-lag])) for lag in lags]\n",
        "            poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
        "            return poly[0]\n",
        "\n",
        "        df['hurst_20'] = df['close'].rolling(100).apply(hurst_exponent, raw=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def add_target_variables(self):\n",
        "        \"\"\"Variables objetivo para el modelo\"\"\"\n",
        "        df = self.df\n",
        "\n",
        "        # Retornos futuros (1h, 4h, 24h)\n",
        "        df['target_1h'] = df['close'].shift(-1) / df['close'] - 1\n",
        "        df['target_4h'] = df['close'].shift(-4) / df['close'] - 1\n",
        "        df['target_24h'] = df['close'].shift(-24) / df['close'] - 1\n",
        "\n",
        "        # Dirección del mercado\n",
        "        df['target_direction_1h'] = np.where(df['target_1h'] > 0, 1, 0)\n",
        "        df['target_direction_4h'] = np.where(df['target_4h'] > 0, 1, 0)\n",
        "\n",
        "        # Volatilidad futura\n",
        "        df['target_volatility_4h'] = df['returns'].shift(-4).rolling(4).std()\n",
        "\n",
        "        return df\n",
        "\n",
        "    def engineer_all_features(self):\n",
        "        \"\"\"Ejecutar todo el feature engineering\"\"\"\n",
        "        df = self.add_price_features()\n",
        "        df = self.add_technical_indicators()\n",
        "        df = self.add_time_features()\n",
        "        df = self.add_statistical_features()\n",
        "        df = self.add_target_variables()\n",
        "\n",
        "        # Eliminar filas con NaN\n",
        "        df = df.dropna()\n",
        "\n",
        "        return df\n",
        "\n",
        "# Aplicar feature engineering\n",
        "feature_engineer = AdvancedFeatureEngineer(df)\n",
        "df_enhanced = feature_engineer.engineer_all_features()\n",
        "\n",
        "print(f\"Dataset después del feature engineering: {df_enhanced.shape}\")\n",
        "\n",
        "# =============================================\n",
        "# PREPARACIÓN DE DATOS PARA EL MODELO\n",
        "# =============================================\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class DataPreprocessor:\n",
        "    def __init__(self, df, sequence_length=60, test_size=0.2, val_size=0.1):\n",
        "        self.df = df\n",
        "        self.sequence_length = sequence_length\n",
        "        self.test_size = test_size\n",
        "        self.val_size = val_size\n",
        "        self.scalers = {}\n",
        "\n",
        "    def prepare_features(self):\n",
        "        \"\"\"Seleccionar y preparar características\"\"\"\n",
        "        # Excluir columnas no numéricas y targets\n",
        "        exclude_cols = ['date', 'target_1h', 'target_4h', 'target_24h',\n",
        "                       'target_direction_1h', 'target_direction_4h', 'target_volatility_4h']\n",
        "\n",
        "        feature_cols = [col for col in self.df.columns if col not in exclude_cols]\n",
        "\n",
        "        # Separar características y targets\n",
        "        X = self.df[feature_cols].values\n",
        "        y_regression = self.df[['target_1h', 'target_4h', 'target_24h']].values\n",
        "        y_classification = self.df[['target_direction_1h', 'target_direction_4h']].values\n",
        "\n",
        "        return X, y_regression, y_classification, feature_cols\n",
        "\n",
        "    def create_sequences(self, X, y_reg, y_clf):\n",
        "        \"\"\"Crear secuencias para LSTM\"\"\"\n",
        "        X_seq, y_reg_seq, y_clf_seq = [], [], []\n",
        "\n",
        "        for i in range(self.sequence_length, len(X)):\n",
        "            X_seq.append(X[i-self.sequence_length:i])\n",
        "            y_reg_seq.append(y_reg[i])\n",
        "            y_clf_seq.append(y_clf[i])\n",
        "\n",
        "        return np.array(X_seq), np.array(y_reg_seq), np.array(y_clf_seq)\n",
        "\n",
        "    def scale_features(self, X_train, X_val, X_test):\n",
        "        \"\"\"Escalar características de forma robusta\"\"\"\n",
        "        # RobustScaler es mejor para datos financieros con outliers\n",
        "        scaler = RobustScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1]))\n",
        "        X_val_scaled = scaler.transform(X_val.reshape(-1, X_val.shape[-1]))\n",
        "        X_test_scaled = scaler.transform(X_test.reshape(-1, X_test.shape[-1]))\n",
        "\n",
        "        # Reshape back to sequences\n",
        "        X_train_scaled = X_train_scaled.reshape(X_train.shape)\n",
        "        X_val_scaled = X_val_scaled.reshape(X_val.shape)\n",
        "        X_test_scaled = X_test_scaled.reshape(X_test.shape)\n",
        "\n",
        "        self.scalers['feature'] = scaler\n",
        "        return X_train_scaled, X_val_scaled, X_test_scaled\n",
        "\n",
        "    def prepare_datasets(self):\n",
        "        \"\"\"Preparar todos los datasets\"\"\"\n",
        "        X, y_reg, y_clf, feature_cols = self.prepare_features()\n",
        "\n",
        "        # Crear secuencias\n",
        "        X_seq, y_reg_seq, y_clf_seq = self.create_sequences(X, y_reg, y_clf)\n",
        "\n",
        "        # Split temporal (importante para time series)\n",
        "        split_idx1 = int(len(X_seq) * (1 - self.test_size - self.val_size))\n",
        "        split_idx2 = int(len(X_seq) * (1 - self.test_size))\n",
        "\n",
        "        X_train, X_val, X_test = (X_seq[:split_idx1],\n",
        "                                 X_seq[split_idx1:split_idx2],\n",
        "                                 X_seq[split_idx2:])\n",
        "\n",
        "        y_reg_train, y_reg_val, y_reg_test = (y_reg_seq[:split_idx1],\n",
        "                                            y_reg_seq[split_idx1:split_idx2],\n",
        "                                            y_reg_seq[split_idx2:])\n",
        "\n",
        "        y_clf_train, y_clf_val, y_clf_test = (y_clf_seq[:split_idx1],\n",
        "                                            y_clf_seq[split_idx1:split_idx2],\n",
        "                                            y_clf_seq[split_idx2:])\n",
        "\n",
        "        # Escalar características\n",
        "        X_train_scaled, X_val_scaled, X_test_scaled = self.scale_features(X_train, X_val, X_test)\n",
        "\n",
        "        print(f\"Training set: {X_train_scaled.shape}\")\n",
        "        print(f\"Validation set: {X_val_scaled.shape}\")\n",
        "        print(f\"Test set: {X_test_scaled.shape}\")\n",
        "\n",
        "        return (X_train_scaled, X_val_scaled, X_test_scaled,\n",
        "                y_reg_train, y_reg_val, y_reg_test,\n",
        "                y_clf_train, y_clf_val, y_clf_test,\n",
        "                feature_cols)\n",
        "\n",
        "# Preparar datos\n",
        "preprocessor = DataPreprocessor(df_enhanced, sequence_length=60)\n",
        "(X_train, X_val, X_test,\n",
        " y_reg_train, y_reg_val, y_reg_test,\n",
        " y_clf_train, y_clf_val, y_clf_test,\n",
        " feature_cols) = preprocessor.prepare_datasets()\n",
        "\n",
        "# =============================================\n",
        "# ARQUITECTURA DEL MODELO NEURONAL AVANZADO\n",
        "# =============================================\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (LSTM, Dense, Input, Conv1D, MaxPooling1D,\n",
        "                                   Flatten, Dropout, BatchNormalization,\n",
        "                                   Attention, MultiHeadAttention, GlobalAveragePooling1D,\n",
        "                                   concatenate)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import (ReduceLROnPlateau, EarlyStopping,\n",
        "                                      ModelCheckpoint, TensorBoard)\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "class AdvancedTradingModel:\n",
        "    def __init__(self, sequence_length, n_features):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.n_features = n_features\n",
        "\n",
        "    def build_hybrid_model(self):\n",
        "        \"\"\"Modelo híbrido CNN-LSTM-Attention\"\"\"\n",
        "        # Input\n",
        "        input_layer = Input(shape=(self.sequence_length, self.n_features))\n",
        "\n",
        "        # CNN Branch para patrones locales\n",
        "        conv1 = Conv1D(filters=64, kernel_size=3, activation='relu',\n",
        "                      kernel_regularizer=l2(1e-4))(input_layer)\n",
        "        conv1 = BatchNormalization()(conv1)\n",
        "        conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "        conv2 = Conv1D(filters=128, kernel_size=3, activation='relu',\n",
        "                      kernel_regularizer=l2(1e-4))(conv1)\n",
        "        conv2 = BatchNormalization()(conv2)\n",
        "        conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "        conv3 = Conv1D(filters=256, kernel_size=3, activation='relu',\n",
        "                      kernel_regularizer=l2(1e-4))(conv2)\n",
        "        conv3 = BatchNormalization()(conv3)\n",
        "\n",
        "        # LSTM Branch para dependencias temporales\n",
        "        lstm1 = LSTM(256, return_sequences=True,\n",
        "                    kernel_regularizer=l2(1e-4))(input_layer)\n",
        "        lstm1 = BatchNormalization()(lstm1)\n",
        "        lstm1 = Dropout(0.3)(lstm1)\n",
        "\n",
        "        lstm2 = LSTM(128, return_sequences=True,\n",
        "                    kernel_regularizer=l2(1e-4))(lstm1)\n",
        "        lstm2 = BatchNormalization()(lstm2)\n",
        "        lstm2 = Dropout(0.3)(lstm2)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attention = MultiHeadAttention(num_heads=8, key_dim=64)(lstm2, lstm2)\n",
        "        attention = BatchNormalization()(attention)\n",
        "\n",
        "        # Combine CNN and LSTM branches\n",
        "        cnn_flat = GlobalAveragePooling1D()(conv3)\n",
        "        lstm_flat = GlobalAveragePooling1D()(attention)\n",
        "\n",
        "        # Concatenate all branches\n",
        "        concatenated = concatenate([cnn_flat, lstm_flat])\n",
        "\n",
        "        # Dense layers\n",
        "        dense1 = Dense(512, activation='relu', kernel_regularizer=l2(1e-4))(concatenated)\n",
        "        dense1 = BatchNormalization()(dense1)\n",
        "        dense1 = Dropout(0.4)(dense1)\n",
        "\n",
        "        dense2 = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(dense1)\n",
        "        dense2 = BatchNormalization()(dense2)\n",
        "        dense2 = Dropout(0.4)(dense2)\n",
        "\n",
        "        dense3 = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(dense2)\n",
        "        dense3 = BatchNormalization()(dense3)\n",
        "        dense3 = Dropout(0.3)(dense3)\n",
        "\n",
        "        # Multi-output\n",
        "        # Regression outputs\n",
        "        reg_output1 = Dense(1, activation='linear', name='return_1h')(dense3)\n",
        "        reg_output2 = Dense(1, activation='linear', name='return_4h')(dense3)\n",
        "        reg_output3 = Dense(1, activation='linear', name='return_24h')(dense3)\n",
        "\n",
        "        # Classification outputs\n",
        "        clf_output1 = Dense(1, activation='sigmoid', name='direction_1h')(dense3)\n",
        "        clf_output2 = Dense(1, activation='sigmoid', name='direction_4h')(dense3)\n",
        "\n",
        "        model = Model(inputs=input_layer,\n",
        "                     outputs=[reg_output1, reg_output2, reg_output3,\n",
        "                             clf_output1, clf_output2])\n",
        "\n",
        "        return model\n",
        "\n",
        "# Construir modelo\n",
        "model_builder = AdvancedTradingModel(sequence_length=60, n_features=X_train.shape[2])\n",
        "model = model_builder.build_hybrid_model()\n",
        "\n",
        "# Compilar modelo con diferentes losses y metrics\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001, clipvalue=1.0),\n",
        "    loss={\n",
        "        'return_1h': 'mse',\n",
        "        'return_4h': 'mse',\n",
        "        'return_24h': 'mse',\n",
        "        'direction_1h': 'binary_crossentropy',\n",
        "        'direction_4h': 'binary_crossentropy'\n",
        "    },\n",
        "    loss_weights={\n",
        "        'return_1h': 1.0,\n",
        "        'return_4h': 1.0,\n",
        "        'return_24h': 0.5,\n",
        "        'direction_1h': 2.0,\n",
        "        'direction_4h': 1.5\n",
        "    },\n",
        "    metrics={\n",
        "        'return_1h': ['mae', 'mse'],\n",
        "        'return_4h': ['mae', 'mse'],\n",
        "        'return_24h': ['mae', 'mse'],\n",
        "        'direction_1h': ['accuracy', 'binary_accuracy'],\n",
        "        'direction_4h': ['accuracy', 'binary_accuracy']\n",
        "    }\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# =============================================\n",
        "# ENTRENAMIENTO DEL MODELO\n",
        "# =============================================\n",
        "\n",
        "# Callbacks avanzados\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=30,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        'best_trading_model.h5',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    TensorBoard(\n",
        "        log_dir='./logs',\n",
        "        histogram_freq=1,\n",
        "        update_freq='epoch'\n",
        "    )\n",
        "]\n",
        "\n",
        "# SOLUCIÓN: Configurar todo el modelo dentro del strategy scope\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n",
        "\n",
        "with strategy.scope():\n",
        "    # Construir y compilar el modelo completamente dentro del scope\n",
        "    model_builder = AdvancedTradingModel(sequence_length=60, n_features=X_train.shape[2])\n",
        "    model = model_builder.build_hybrid_model()\n",
        "\n",
        "    # Compilar modelo dentro del scope\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001, clipvalue=1.0),\n",
        "        loss={\n",
        "            'return_1h': 'mse',\n",
        "            'return_4h': 'mse',\n",
        "            'return_24h': 'mse',\n",
        "            'direction_1h': 'binary_crossentropy',\n",
        "            'direction_4h': 'binary_crossentropy'\n",
        "        },\n",
        "        loss_weights={\n",
        "            'return_1h': 1.0,\n",
        "            'return_4h': 1.0,\n",
        "            'return_24h': 0.5,\n",
        "            'direction_1h': 2.0,\n",
        "            'direction_4h': 1.5\n",
        "        },\n",
        "        metrics={\n",
        "            'return_1h': ['mae', 'mse'],\n",
        "            'return_4h': ['mae', 'mse'],\n",
        "            'return_24h': ['mae', 'mse'],\n",
        "            'direction_1h': ['accuracy', 'binary_accuracy'],\n",
        "            'direction_4h': ['accuracy', 'binary_accuracy']\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"Modelo compilado exitosamente dentro del strategy scope!\")\n",
        "\n",
        "# Ajustar batch size para distribución\n",
        "batch_size = BATCH_SIZE\n",
        "print(f\"Batch size ajustado: {batch_size}\")\n",
        "\n",
        "# Entrenar modelo\n",
        "print(\"Iniciando entrenamiento...\")\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    {\n",
        "        'return_1h': y_reg_train[:, 0],\n",
        "        'return_4h': y_reg_train[:, 1],\n",
        "        'return_24h': y_reg_train[:, 2],\n",
        "        'direction_1h': y_clf_train[:, 0],\n",
        "        'direction_4h': y_clf_train[:, 1]\n",
        "    },\n",
        "    batch_size=batch_size,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(\n",
        "        X_val,\n",
        "        {\n",
        "            'return_1h': y_reg_val[:, 0],\n",
        "            'return_4h': y_reg_val[:, 1],\n",
        "            'return_24h': y_reg_val[:, 2],\n",
        "            'direction_1h': y_clf_val[:, 0],\n",
        "            'direction_4h': y_clf_val[:, 1]\n",
        "        }\n",
        "    ),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        "    shuffle=False  # Importante para time series\n",
        ")\n",
        "\n",
        "# =============================================\n",
        "# EVALUACIÓN Y ANÁLISIS DEL MODELO\n",
        "# =============================================\n",
        "\n",
        "def evaluate_model_comprehensive(model, X_test, y_reg_test, y_clf_test):\n",
        "    \"\"\"Evaluación comprehensiva del modelo - VERSIÓN CORREGIDA\"\"\"\n",
        "    # Predecir\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Evaluación de regresión\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "    print(\"=== EVALUACIÓN DE REGRESIÓN ===\")\n",
        "    horizons = ['1H', '4H', '24H']\n",
        "\n",
        "    for i, horizon in enumerate(horizons):\n",
        "        # CORRECCIÓN: Asegurar que las predicciones tengan la forma correcta\n",
        "        y_true_reg = y_reg_test[:, i]\n",
        "        y_pred_reg = predictions[i].flatten()  # Aplanar las predicciones\n",
        "\n",
        "        mse = mean_squared_error(y_true_reg, y_pred_reg)\n",
        "        mae = mean_absolute_error(y_true_reg, y_pred_reg)\n",
        "        r2 = r2_score(y_true_reg, y_pred_reg)\n",
        "\n",
        "        print(f\"Horizonte {horizon}:\")\n",
        "        print(f\"  MSE: {mse:.6f}\")\n",
        "        print(f\"  MAE: {mae:.6f}\")\n",
        "        print(f\"  R²: {r2:.4f}\")\n",
        "\n",
        "    # Evaluación de clasificación\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "    print(\"\\n=== EVALUACIÓN DE CLASIFICACIÓN ===\")\n",
        "    directions = ['1H', '4H']\n",
        "\n",
        "    for i, direction in enumerate(directions):\n",
        "        # CORRECCIÓN: Índices correctos para clasificación\n",
        "        # Los outputs 3 y 4 son direction_1h y direction_4h\n",
        "        pred_probs = predictions[i + 3].flatten()  # Aplanar probabilidades\n",
        "        pred_binary = (pred_probs > 0.5).astype(int)\n",
        "\n",
        "        y_true_clf = y_clf_test[:, i]\n",
        "\n",
        "        acc = accuracy_score(y_true_clf, pred_binary)\n",
        "        precision = precision_score(y_true_clf, pred_binary, zero_division=0)\n",
        "        recall = recall_score(y_true_clf, pred_binary, zero_division=0)\n",
        "        f1 = f1_score(y_true_clf, pred_binary, zero_division=0)\n",
        "\n",
        "        print(f\"Dirección {direction}:\")\n",
        "        print(f\"  Accuracy: {acc:.4f}\")\n",
        "        print(f\"  Precision: {precision:.4f}\")\n",
        "        print(f\"  Recall: {recall:.4f}\")\n",
        "        print(f\"  F1-Score: {f1:.4f}\")\n",
        "\n",
        "        # Matriz de confusión\n",
        "        cm = confusion_matrix(y_true_clf, pred_binary)\n",
        "        print(f\"  Matriz de confusión:\\n{cm}\")\n",
        "\n",
        "# Evaluar modelo\n",
        "evaluate_model_comprehensive(model, X_test, y_reg_test, y_clf_test)\n",
        "\n",
        "# =============================================\n",
        "# BACKTESTING Y SIMULACIÓN DE TRADING\n",
        "# =============================================\n",
        "\n",
        "class TradingSimulator:\n",
        "    def __init__(self, model, df, preprocessor):\n",
        "        self.model = model\n",
        "        self.df = df\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def generate_signals(self, X_data, threshold=0.6):\n",
        "        \"\"\"Generar señales de trading - VERSIÓN CORREGIDA\"\"\"\n",
        "        predictions = self.model.predict(X_data)\n",
        "\n",
        "        # CORRECCIÓN: Usar el output correcto para direction_1h (índice 3)\n",
        "        direction_probs = predictions[3]  # direction_1h\n",
        "        signals = np.where(direction_probs > threshold, 1,\n",
        "                          np.where(direction_probs < (1 - threshold), -1, 0))\n",
        "\n",
        "        return signals.flatten(), direction_probs.flatten()\n",
        "\n",
        "    def simulate_trading(self, initial_capital=10000, transaction_cost=0.0002):\n",
        "        \"\"\"Simular estrategia de trading - VERSIÓN CORREGIDA\"\"\"\n",
        "        # Obtener señales para test set\n",
        "        signals, probabilities = self.generate_signals(X_test)\n",
        "\n",
        "        # CORRECCIÓN: Calcular correctamente los índices de test\n",
        "        test_start_idx = len(self.df) - len(X_test) - 60  # Restar sequence_length\n",
        "        prices = self.df['close'].iloc[test_start_idx:test_start_idx + len(signals)].values\n",
        "\n",
        "        # Inicializar portfolio\n",
        "        capital = initial_capital\n",
        "        position = 0\n",
        "        portfolio_value = []\n",
        "        trades = []\n",
        "\n",
        "        for i in range(len(signals)):\n",
        "            current_price = prices[i]\n",
        "\n",
        "            # Ejecutar señal\n",
        "            if signals[i] == 1 and position <= 0:  # Señal de compra\n",
        "                if position < 0:  # Cerrar short primero\n",
        "                    capital += abs(position) * current_price * (1 - transaction_cost)\n",
        "                    position = 0\n",
        "\n",
        "                # Abrir long\n",
        "                units = capital * 0.98 / current_price  # Usar 98% del capital\n",
        "                position = units\n",
        "                capital -= units * current_price * (1 + transaction_cost)\n",
        "                trades.append(('BUY', current_price, probabilities[i]))\n",
        "\n",
        "            elif signals[i] == -1 and position >= 0:  # Señal de venta\n",
        "                if position > 0:  # Cerrar long primero\n",
        "                    capital += position * current_price * (1 - transaction_cost)\n",
        "                    position = 0\n",
        "\n",
        "                # Abrir short\n",
        "                units = capital * 0.98 / current_price\n",
        "                position = -units\n",
        "                capital += units * current_price * (1 - transaction_cost)\n",
        "                trades.append(('SELL', current_price, probabilities[i]))\n",
        "\n",
        "            # Calcular valor del portfolio\n",
        "            portfolio_value.append(capital + position * current_price)\n",
        "\n",
        "        # Cerrar posición final\n",
        "        if position != 0:\n",
        "            capital += position * prices[-1] * (1 - transaction_cost)\n",
        "            portfolio_value[-1] = capital  # Actualizar último valor\n",
        "\n",
        "        return portfolio_value, trades, capital\n",
        "\n",
        "# Ejecutar simulación\n",
        "simulator = TradingSimulator(model, df_enhanced, preprocessor)\n",
        "portfolio_values, trades, final_capital = simulator.simulate_trading()\n",
        "\n",
        "# Análisis de performance\n",
        "initial_capital = 10000\n",
        "total_return = (final_capital - initial_capital) / initial_capital * 100\n",
        "print(f\"Retorno total: {total_return:.2f}%\")\n",
        "print(f\"Número de trades: {len(trades)}\")\n",
        "print(f\"Capital final: ${final_capital:.2f}\")\n",
        "\n",
        "# =============================================\n",
        "# VISUALIZACIONES AVANZADAS\n",
        "# =============================================\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def create_comprehensive_visualizations(history, portfolio_values, df_enhanced, trades):\n",
        "    \"\"\"Crear visualizaciones comprehensivas\"\"\"\n",
        "\n",
        "    # 1. Pérdidas del entrenamiento\n",
        "    fig1 = make_subplots(rows=2, cols=2, subplot_titles=['Loss', 'Direction Accuracy', 'Returns MAE', 'Learning Rate'])\n",
        "\n",
        "    # Loss\n",
        "    fig1.add_trace(go.Scatter(y=history.history['loss'], name='Train Loss'), row=1, col=1)\n",
        "    fig1.add_trace(go.Scatter(y=history.history['val_loss'], name='Val Loss'), row=1, col=1)\n",
        "\n",
        "    # Accuracy\n",
        "    fig1.add_trace(go.Scatter(y=history.history['direction_1h_accuracy'], name='Train Acc 1H'), row=1, col=2)\n",
        "    fig1.add_trace(go.Scatter(y=history.history['val_direction_1h_accuracy'], name='Val Acc 1H'), row=1, col=2)\n",
        "\n",
        "    # MAE\n",
        "    fig1.add_trace(go.Scatter(y=history.history['return_1h_mae'], name='Train MAE 1H'), row=2, col=1)\n",
        "    fig1.add_trace(go.Scatter(y=history.history['val_return_1h_mae'], name='Val MAE 1H'), row=2, col=1)\n",
        "\n",
        "    fig1.update_layout(height=800, title_text=\"Métricas de Entrenamiento\")\n",
        "    fig1.show()\n",
        "\n",
        "    # 2. Performance de trading\n",
        "    fig2 = go.Figure()\n",
        "    fig2.add_trace(go.Scatter(y=portfolio_values, name='Portfolio Value', line=dict(color='blue')))\n",
        "\n",
        "    # Marcar trades\n",
        "    buy_trades = [t for t in trades if t[0] == 'BUY']\n",
        "    sell_trades = [t for t in trades if t[0] == 'SELL']\n",
        "\n",
        "    if buy_trades:\n",
        "        buy_indices = [portfolio_values.index(portfolio_values[-len(buy_trades):][i]) for i in range(len(buy_trades))]\n",
        "        fig2.add_trace(go.Scatter(x=buy_indices, y=[portfolio_values[i] for i in buy_indices],\n",
        "                             mode='markers', name='Buy', marker=dict(color='green', size=10)))\n",
        "\n",
        "    if sell_trades:\n",
        "        sell_indices = [portfolio_values.index(portfolio_values[-len(sell_trades):][i]) for i in range(len(sell_trades))]\n",
        "        fig2.add_trace(go.Scatter(x=sell_indices, y=[portfolio_values[i] for i in sell_indices],\n",
        "                             mode='markers', name='Sell', marker=dict(color='red', size=10)))\n",
        "\n",
        "    fig2.update_layout(title=f\"Simulación de Trading - Retorno: {total_return:.2f}%\",\n",
        "                      xaxis_title=\"Tiempo\", yaxis_title=\"Valor del Portfolio\")\n",
        "    fig2.show()\n",
        "\n",
        "# Generar visualizaciones\n",
        "create_comprehensive_visualizations(history, portfolio_values, df_enhanced, trades)\n",
        "\n",
        "# =============================================\n",
        "# GUARDAR MODELO Y RECURSOS\n",
        "# =============================================\n",
        "\n",
        "# Guardar modelo completo\n",
        "model.save('gbpusd_trading_model.h5')\n",
        "\n",
        "# Guardar preprocessor\n",
        "import pickle\n",
        "with open('preprocessor.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor, f)\n",
        "\n",
        "# Guardar feature columns\n",
        "with open('feature_columns.pkl', 'wb') as f:\n",
        "    pickle.dump(feature_cols, f)\n",
        "\n",
        "print(\"Modelo y recursos guardados exitosamente!\")\n",
        "\n",
        "# =============================================\n",
        "# INFERENCIA EN TIEMPO REAL (EJEMPLO)\n",
        "# =============================================\n",
        "\n",
        "class RealTimePredictor:\n",
        "    def __init__(self, model_path, preprocessor_path, feature_cols_path):\n",
        "        self.model = tf.keras.models.load_model(model_path)\n",
        "        with open(preprocessor_path, 'rb') as f:\n",
        "            self.preprocessor = pickle.load(f)\n",
        "        with open(feature_cols_path, 'rb') as f:\n",
        "            self.feature_cols = pickle.load(f)\n",
        "\n",
        "    def prepare_realtime_data(self, recent_data):\n",
        "        \"\"\"Preparar datos para predicción en tiempo real\"\"\"\n",
        "        # Escalar datos\n",
        "        scaled_data = self.preprocessor.scalers['feature'].transform(recent_data)\n",
        "        return scaled_data.reshape(1, len(recent_data), len(self.feature_cols))\n",
        "\n",
        "    def predict(self, recent_data):\n",
        "        \"\"\"Realizar predicción\"\"\"\n",
        "        prepared_data = self.prepare_realtime_data(recent_data)\n",
        "        predictions = self.model.predict(prepared_data)\n",
        "\n",
        "        return {\n",
        "            'return_1h': predictions[0][0][0],\n",
        "            'return_4h': predictions[1][0][0],\n",
        "            'return_24h': predictions[2][0][0],\n",
        "            'direction_1h_prob': predictions[3][0][0],\n",
        "            'direction_4h_prob': predictions[4][0][0],\n",
        "            'signal_1h': 'BUY' if predictions[3][0][0] > 0.6 else 'SELL' if predictions[3][0][0] < 0.4 else 'HOLD'\n",
        "        }\n",
        "\n",
        "# Ejemplo de uso (comentado)\n",
        "# predictor = RealTimePredictor('gbpusd_trading_model.h5', 'preprocessor.pkl', 'feature_columns.pkl')\n",
        "# recent_data = df_enhanced[self.feature_cols].tail(60).values\n",
        "# prediction = predictor.predict(recent_data)\n",
        "# print(\"Predicción en tiempo real:\", prediction)"
      ]
    }
  ]
}
